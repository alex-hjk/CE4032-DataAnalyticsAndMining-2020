{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "# from sklearn.preprocessing import normalize\n",
    "# import scipy.cluster.hierarchy as shc\n",
    "# from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeeeeehan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (62,63,64,80,95,97) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/yeeeeehan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (5,32,34,54,55,56,62,63,64,77,80,95,97,115,116,122) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read in dataset and select columns\n",
    "\n",
    "l = pd.read_csv('labelled.csv')\n",
    "u = pd.read_csv('unlabelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled = l.set_index('eventid')\n",
    "unlabelled = u.set_index('eventid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in labelled: 28139\n",
      "Number of rows in unlabelled: 163325\n",
      "# of rows in labelled as a % of # of rows in unlabelled: 17.23%\n",
      "\n",
      "Minimum value of %_of_unlabelled: 8.7%\n",
      "Minimum value of %_of_unlabelled: 34.51%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labelled_year_count</th>\n",
       "      <th>unlabelled_year_count</th>\n",
       "      <th>%_of_unlabelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>130</td>\n",
       "      <td>521</td>\n",
       "      <td>24.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>56</td>\n",
       "      <td>415</td>\n",
       "      <td>13.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>46</td>\n",
       "      <td>522</td>\n",
       "      <td>8.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>84</td>\n",
       "      <td>389</td>\n",
       "      <td>21.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>70</td>\n",
       "      <td>511</td>\n",
       "      <td>13.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>64</td>\n",
       "      <td>676</td>\n",
       "      <td>9.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>84</td>\n",
       "      <td>839</td>\n",
       "      <td>10.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>147</td>\n",
       "      <td>1172</td>\n",
       "      <td>12.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>289</td>\n",
       "      <td>1237</td>\n",
       "      <td>23.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>478</td>\n",
       "      <td>2184</td>\n",
       "      <td>21.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>387</td>\n",
       "      <td>2274</td>\n",
       "      <td>17.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>330</td>\n",
       "      <td>2256</td>\n",
       "      <td>14.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>275</td>\n",
       "      <td>2269</td>\n",
       "      <td>12.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>325</td>\n",
       "      <td>2545</td>\n",
       "      <td>12.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>480</td>\n",
       "      <td>3015</td>\n",
       "      <td>15.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>341</td>\n",
       "      <td>2574</td>\n",
       "      <td>13.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>297</td>\n",
       "      <td>2563</td>\n",
       "      <td>11.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>366</td>\n",
       "      <td>2817</td>\n",
       "      <td>12.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>307</td>\n",
       "      <td>3413</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>346</td>\n",
       "      <td>3978</td>\n",
       "      <td>8.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>329</td>\n",
       "      <td>3558</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>474</td>\n",
       "      <td>4209</td>\n",
       "      <td>11.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>651</td>\n",
       "      <td>4420</td>\n",
       "      <td>14.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>382</td>\n",
       "      <td>3074</td>\n",
       "      <td>12.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>317</td>\n",
       "      <td>2764</td>\n",
       "      <td>11.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>336</td>\n",
       "      <td>2722</td>\n",
       "      <td>12.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>529</td>\n",
       "      <td>2670</td>\n",
       "      <td>19.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>116</td>\n",
       "      <td>818</td>\n",
       "      <td>14.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>262</td>\n",
       "      <td>1133</td>\n",
       "      <td>23.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>328</td>\n",
       "      <td>1496</td>\n",
       "      <td>21.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>357</td>\n",
       "      <td>1556</td>\n",
       "      <td>22.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>342</td>\n",
       "      <td>991</td>\n",
       "      <td>34.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>282</td>\n",
       "      <td>996</td>\n",
       "      <td>28.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>203</td>\n",
       "      <td>963</td>\n",
       "      <td>21.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>404</td>\n",
       "      <td>1613</td>\n",
       "      <td>25.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>362</td>\n",
       "      <td>2396</td>\n",
       "      <td>15.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>555</td>\n",
       "      <td>2687</td>\n",
       "      <td>20.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>687</td>\n",
       "      <td>4118</td>\n",
       "      <td>16.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>619</td>\n",
       "      <td>4103</td>\n",
       "      <td>15.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>692</td>\n",
       "      <td>4134</td>\n",
       "      <td>16.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>809</td>\n",
       "      <td>4267</td>\n",
       "      <td>18.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>1329</td>\n",
       "      <td>7200</td>\n",
       "      <td>18.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2051</td>\n",
       "      <td>9990</td>\n",
       "      <td>20.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2381</td>\n",
       "      <td>14527</td>\n",
       "      <td>16.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2565</td>\n",
       "      <td>12412</td>\n",
       "      <td>20.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2303</td>\n",
       "      <td>11323</td>\n",
       "      <td>20.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2006</td>\n",
       "      <td>8974</td>\n",
       "      <td>22.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1566</td>\n",
       "      <td>8041</td>\n",
       "      <td>19.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      labelled_year_count  unlabelled_year_count  %_of_unlabelled\n",
       "1970                  130                    521            24.95\n",
       "1971                   56                    415            13.49\n",
       "1972                   46                    522             8.81\n",
       "1973                   84                    389            21.59\n",
       "1974                   70                    511            13.70\n",
       "1975                   64                    676             9.47\n",
       "1976                   84                    839            10.01\n",
       "1977                  147                   1172            12.54\n",
       "1978                  289                   1237            23.36\n",
       "1979                  478                   2184            21.89\n",
       "1980                  387                   2274            17.02\n",
       "1981                  330                   2256            14.63\n",
       "1982                  275                   2269            12.12\n",
       "1983                  325                   2545            12.77\n",
       "1984                  480                   3015            15.92\n",
       "1985                  341                   2574            13.25\n",
       "1986                  297                   2563            11.59\n",
       "1987                  366                   2817            12.99\n",
       "1988                  307                   3413             9.00\n",
       "1989                  346                   3978             8.70\n",
       "1990                  329                   3558             9.25\n",
       "1991                  474                   4209            11.26\n",
       "1992                  651                   4420            14.73\n",
       "1994                  382                   3074            12.43\n",
       "1995                  317                   2764            11.47\n",
       "1996                  336                   2722            12.34\n",
       "1997                  529                   2670            19.81\n",
       "1998                  116                    818            14.18\n",
       "1999                  262                   1133            23.12\n",
       "2000                  328                   1496            21.93\n",
       "2001                  357                   1556            22.94\n",
       "2002                  342                    991            34.51\n",
       "2003                  282                    996            28.31\n",
       "2004                  203                    963            21.08\n",
       "2005                  404                   1613            25.05\n",
       "2006                  362                   2396            15.11\n",
       "2007                  555                   2687            20.66\n",
       "2008                  687                   4118            16.68\n",
       "2009                  619                   4103            15.09\n",
       "2010                  692                   4134            16.74\n",
       "2011                  809                   4267            18.96\n",
       "2012                 1329                   7200            18.46\n",
       "2013                 2051                   9990            20.53\n",
       "2014                 2381                  14527            16.39\n",
       "2015                 2565                  12412            20.67\n",
       "2016                 2303                  11323            20.34\n",
       "2017                 2006                   8974            22.35\n",
       "2018                 1566                   8041            19.48"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of labelled and unlabelled rows by year \n",
    "\n",
    "print(f\"Number of rows in labelled: {labelled.shape[0]}\")\n",
    "print(f\"Number of rows in unlabelled: {unlabelled.shape[0]}\")\n",
    "print(f\"# of rows in labelled as a % of # of rows in unlabelled: {round(labelled.shape[0]/unlabelled.shape[0] * 100, 2)}%\\n\")\n",
    "\n",
    "year_distribution = labelled[\"iyear\"].value_counts().to_frame().join(unlabelled[\"iyear\"].value_counts(), lsuffix = \"_left\").sort_index()\n",
    "year_distribution.columns = ['labelled_year_count','unlabelled_year_count']\n",
    "year_distribution['%_of_unlabelled'] = round(year_distribution['labelled_year_count'] / year_distribution['unlabelled_year_count'] * 100, 2)\n",
    "print(f\"Minimum value of %_of_unlabelled: {year_distribution['%_of_unlabelled'].min()}%\")\n",
    "print(f\"Minimum value of %_of_unlabelled: {year_distribution['%_of_unlabelled'].max()}%\")\n",
    "year_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce nkillwound column\n",
    "\n",
    "labelled['nkillwound'] = labelled['nkill'] + labelled['nwound']\n",
    "unlabelled['nkillwound'] = unlabelled['nkill'] + unlabelled['nwound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying columns to perform ML on\n",
    "\n",
    "cols_for_learning_nperps = ['region','nperps','attacktype1','targtype1','weaptype1', 'cluster']\n",
    "cols_for_learning_nkillwound = ['region','nkillwound','attacktype1','targtype1','weaptype1', 'cluster']\n",
    "\n",
    "\n",
    "# extra_cols = ['extended', 'success', 'suicide', #'property'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nperps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unlabelled rows:\n",
      "163325\n",
      "\n",
      "Number of unlabelled rows with valid nperps\n",
      "1940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>iyear</th>\n",
       "      <th>imonth</th>\n",
       "      <th>iday</th>\n",
       "      <th>approxdate</th>\n",
       "      <th>extended</th>\n",
       "      <th>resolution</th>\n",
       "      <th>country</th>\n",
       "      <th>country_txt</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>scite2</th>\n",
       "      <th>scite3</th>\n",
       "      <th>dbsource</th>\n",
       "      <th>INT_LOG</th>\n",
       "      <th>INT_IDEO</th>\n",
       "      <th>INT_MISC</th>\n",
       "      <th>INT_ANY</th>\n",
       "      <th>related</th>\n",
       "      <th>cluster</th>\n",
       "      <th>nkillwound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197002100001</th>\n",
       "      <td>59</td>\n",
       "      <td>1970</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>362</td>\n",
       "      <td>West Germany (FRG)</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PGIS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197007310001</th>\n",
       "      <td>440</td>\n",
       "      <td>1970</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8/6/1970</td>\n",
       "      <td>218</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PGIS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197008090001</th>\n",
       "      <td>456</td>\n",
       "      <td>1970</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PGIS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197009120001</th>\n",
       "      <td>513</td>\n",
       "      <td>1970</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PGIS</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197011210002</th>\n",
       "      <td>611</td>\n",
       "      <td>1970</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PGIS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unnamed: 0  iyear  imonth  iday approxdate  extended resolution  \\\n",
       "eventid                                                                         \n",
       "197002100001          59   1970       2    10        NaN         0        NaN   \n",
       "197007310001         440   1970       7    31        NaN         1   8/6/1970   \n",
       "197008090001         456   1970       8     9        NaN         0        NaN   \n",
       "197009120001         513   1970       9    12        NaN         0        NaN   \n",
       "197011210002         611   1970      11    21        NaN         0        NaN   \n",
       "\n",
       "              country         country_txt  region  ... scite2 scite3 dbsource  \\\n",
       "eventid                                            ...                          \n",
       "197002100001      362  West Germany (FRG)       8  ...    NaN    NaN     PGIS   \n",
       "197007310001      218             Uruguay       3  ...    NaN    NaN     PGIS   \n",
       "197008090001       11           Argentina       3  ...    NaN    NaN     PGIS   \n",
       "197009120001       11           Argentina       3  ...    NaN    NaN     PGIS   \n",
       "197011210002      218             Uruguay       3  ...    NaN    NaN     PGIS   \n",
       "\n",
       "              INT_LOG  INT_IDEO  INT_MISC  INT_ANY related cluster  nkillwound  \n",
       "eventid                                                                         \n",
       "197002100001        0         0         1        1     NaN     NaN         NaN  \n",
       "197007310001        0         1         1        1     NaN     NaN         NaN  \n",
       "197008090001        0         1         1        1     NaN     NaN         NaN  \n",
       "197009120001       -9        -9         0       -9     NaN     NaN         NaN  \n",
       "197011210002        0         0         0        0     NaN     NaN         NaN  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total\n",
    "print('Total number of unlabelled rows:')\n",
    "print(unlabelled.shape[0])\n",
    "\n",
    "# Valid nperps\n",
    "print('\\nNumber of unlabelled rows with valid nperps')\n",
    "print(unlabelled[(unlabelled[\"nperps\"].notnull()) &  (unlabelled[\"nperps\"]!= -99.0)].shape[0])\n",
    "\n",
    "# Introducing unlabelled_nperps\n",
    "unlabelled_nperps = unlabelled[(unlabelled[\"nperps\"].notnull()) &  (unlabelled[\"nperps\"]!= -99.0)]\n",
    "unlabelled_nperps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert all fields to int from float \n",
    "labelled_nperps = labelled[cols_for_learning_nperps].astype('int32')\n",
    "unlabelled_nperps = unlabelled_nperps[cols_for_learning_nperps[:-1]].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Model building\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_split = 0.8\n",
    "# max_words = 1000\n",
    "batch_size = 10000\n",
    "epochs = 600\n",
    "\n",
    "labelled_nperps = labelled_nperps.sample(frac=1) # Shuffle labelled set\n",
    "\n",
    "columns = labelled_nperps[['region','attacktype1','targtype1','weaptype1']].to_numpy()\n",
    "clusters = labelled_nperps['cluster'].to_numpy()\n",
    "\n",
    "num_classes = np.max(clusters) - np.min(clusters) + 1\n",
    "clusters = utils.to_categorical(clusters, num_classes)\n",
    "\n",
    "train_size = int(len(labelled_nperps) * percentage_split) \n",
    "\n",
    "x_train = columns[:train_size]\n",
    "y_train = clusters[:train_size]\n",
    "\n",
    "x_eval = columns[train_size:]\n",
    "y_eval = clusters[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.8734 - accuracy: 0.2154 - val_loss: 1.3790 - val_accuracy: 0.3048\n",
      "Epoch 2/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.6012 - accuracy: 0.2873 - val_loss: 1.3753 - val_accuracy: 0.3857\n",
      "Epoch 3/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.5939 - accuracy: 0.3260 - val_loss: 1.3991 - val_accuracy: 0.4272\n",
      "Epoch 4/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.5906 - accuracy: 0.3455 - val_loss: 1.3643 - val_accuracy: 0.4410\n",
      "Epoch 5/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.5468 - accuracy: 0.3579 - val_loss: 1.3091 - val_accuracy: 0.4355\n",
      "Epoch 6/600\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.4939 - accuracy: 0.3633 - val_loss: 1.2701 - val_accuracy: 0.4355\n",
      "Epoch 7/600\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.4489 - accuracy: 0.3733 - val_loss: 1.2509 - val_accuracy: 0.4299\n",
      "Epoch 8/600\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 1.4407 - accuracy: 0.3757 - val_loss: 1.2474 - val_accuracy: 0.4342\n",
      "Epoch 9/600\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.4267 - accuracy: 0.3791 - val_loss: 1.2458 - val_accuracy: 0.4159\n",
      "Epoch 10/600\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.4233 - accuracy: 0.3807 - val_loss: 1.2373 - val_accuracy: 0.4372\n",
      "Epoch 11/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.4043 - accuracy: 0.3906 - val_loss: 1.2309 - val_accuracy: 0.4219\n",
      "Epoch 12/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.3868 - accuracy: 0.4011 - val_loss: 1.2339 - val_accuracy: 0.4227\n",
      "Epoch 13/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.3723 - accuracy: 0.4094 - val_loss: 1.2402 - val_accuracy: 0.4240\n",
      "Epoch 14/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.3710 - accuracy: 0.4126 - val_loss: 1.2413 - val_accuracy: 0.4264\n",
      "Epoch 15/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.3702 - accuracy: 0.4162 - val_loss: 1.2351 - val_accuracy: 0.4318\n",
      "Epoch 16/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.3534 - accuracy: 0.4177 - val_loss: 1.2258 - val_accuracy: 0.4369\n",
      "Epoch 17/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.3434 - accuracy: 0.4214 - val_loss: 1.2183 - val_accuracy: 0.4365\n",
      "Epoch 18/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.3395 - accuracy: 0.4195 - val_loss: 1.2145 - val_accuracy: 0.4430\n",
      "Epoch 19/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.3276 - accuracy: 0.4194 - val_loss: 1.2125 - val_accuracy: 0.4519\n",
      "Epoch 20/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.3223 - accuracy: 0.4252 - val_loss: 1.2108 - val_accuracy: 0.4602\n",
      "Epoch 21/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.3258 - accuracy: 0.4182 - val_loss: 1.2103 - val_accuracy: 0.4656\n",
      "Epoch 22/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.3050 - accuracy: 0.4251 - val_loss: 1.2113 - val_accuracy: 0.4613\n",
      "Epoch 23/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.3042 - accuracy: 0.4302 - val_loss: 1.2114 - val_accuracy: 0.4664\n",
      "Epoch 24/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.2979 - accuracy: 0.4345 - val_loss: 1.2100 - val_accuracy: 0.4660\n",
      "Epoch 25/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.2936 - accuracy: 0.4383 - val_loss: 1.2076 - val_accuracy: 0.4687\n",
      "Epoch 26/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.2877 - accuracy: 0.4355 - val_loss: 1.2051 - val_accuracy: 0.4738\n",
      "Epoch 27/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.2831 - accuracy: 0.4395 - val_loss: 1.2030 - val_accuracy: 0.4776\n",
      "Epoch 28/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.2781 - accuracy: 0.4407 - val_loss: 1.2016 - val_accuracy: 0.4835\n",
      "Epoch 29/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.2734 - accuracy: 0.4444 - val_loss: 1.2004 - val_accuracy: 0.4846\n",
      "Epoch 30/600\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2731 - accuracy: 0.4466 - val_loss: 1.1993 - val_accuracy: 0.4851\n",
      "Epoch 31/600\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.2671 - accuracy: 0.4496 - val_loss: 1.1983 - val_accuracy: 0.4880\n",
      "Epoch 32/600\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.2609 - accuracy: 0.4544 - val_loss: 1.1974 - val_accuracy: 0.4875\n",
      "Epoch 33/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.2606 - accuracy: 0.4452 - val_loss: 1.1966 - val_accuracy: 0.4888\n",
      "Epoch 34/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.2497 - accuracy: 0.4586 - val_loss: 1.1954 - val_accuracy: 0.4892\n",
      "Epoch 35/600\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.2477 - accuracy: 0.4594 - val_loss: 1.1941 - val_accuracy: 0.4894\n",
      "Epoch 36/600\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.2478 - accuracy: 0.4590 - val_loss: 1.1929 - val_accuracy: 0.4902\n",
      "Epoch 37/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.2453 - accuracy: 0.4596 - val_loss: 1.1915 - val_accuracy: 0.4925\n",
      "Epoch 38/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.2418 - accuracy: 0.4609 - val_loss: 1.1902 - val_accuracy: 0.4941\n",
      "Epoch 39/600\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.2326 - accuracy: 0.4708 - val_loss: 1.1889 - val_accuracy: 0.5015\n",
      "Epoch 40/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.2305 - accuracy: 0.4698 - val_loss: 1.1877 - val_accuracy: 0.5032\n",
      "Epoch 41/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.2327 - accuracy: 0.4660 - val_loss: 1.1866 - val_accuracy: 0.4995\n",
      "Epoch 42/600\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.2252 - accuracy: 0.4718 - val_loss: 1.1856 - val_accuracy: 0.4958\n",
      "Epoch 43/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.2274 - accuracy: 0.4748 - val_loss: 1.1841 - val_accuracy: 0.4995\n",
      "Epoch 44/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.2261 - accuracy: 0.4744 - val_loss: 1.1828 - val_accuracy: 0.4989\n",
      "Epoch 45/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.2185 - accuracy: 0.4795 - val_loss: 1.1816 - val_accuracy: 0.4985\n",
      "Epoch 46/600\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.2223 - accuracy: 0.4777 - val_loss: 1.1804 - val_accuracy: 0.4983\n",
      "Epoch 47/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.2169 - accuracy: 0.4794 - val_loss: 1.1791 - val_accuracy: 0.5021\n",
      "Epoch 48/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.2143 - accuracy: 0.4826 - val_loss: 1.1779 - val_accuracy: 0.5024\n",
      "Epoch 49/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.2104 - accuracy: 0.4802 - val_loss: 1.1768 - val_accuracy: 0.5032\n",
      "Epoch 50/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.2090 - accuracy: 0.4856 - val_loss: 1.1755 - val_accuracy: 0.5034\n",
      "Epoch 51/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.2058 - accuracy: 0.4873 - val_loss: 1.1745 - val_accuracy: 0.5032\n",
      "Epoch 52/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.2088 - accuracy: 0.4855 - val_loss: 1.1738 - val_accuracy: 0.5033\n",
      "Epoch 53/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.2044 - accuracy: 0.4867 - val_loss: 1.1729 - val_accuracy: 0.5033\n",
      "Epoch 54/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1988 - accuracy: 0.4894 - val_loss: 1.1721 - val_accuracy: 0.5033\n",
      "Epoch 55/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.2037 - accuracy: 0.4899 - val_loss: 1.1711 - val_accuracy: 0.5033\n",
      "Epoch 56/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1966 - accuracy: 0.4879 - val_loss: 1.1702 - val_accuracy: 0.5029\n",
      "Epoch 57/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1976 - accuracy: 0.4927 - val_loss: 1.1693 - val_accuracy: 0.5029\n",
      "Epoch 58/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1931 - accuracy: 0.4952 - val_loss: 1.1684 - val_accuracy: 0.5026\n",
      "Epoch 59/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1910 - accuracy: 0.4920 - val_loss: 1.1676 - val_accuracy: 0.5026\n",
      "Epoch 60/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1909 - accuracy: 0.4947 - val_loss: 1.1667 - val_accuracy: 0.5026\n",
      "Epoch 61/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1927 - accuracy: 0.4946 - val_loss: 1.1658 - val_accuracy: 0.5026\n",
      "Epoch 62/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1906 - accuracy: 0.4964 - val_loss: 1.1650 - val_accuracy: 0.5026\n",
      "Epoch 63/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1884 - accuracy: 0.4947 - val_loss: 1.1643 - val_accuracy: 0.5022\n",
      "Epoch 64/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1901 - accuracy: 0.4995 - val_loss: 1.1636 - val_accuracy: 0.5022\n",
      "Epoch 65/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1861 - accuracy: 0.4980 - val_loss: 1.1629 - val_accuracy: 0.5024\n",
      "Epoch 66/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1832 - accuracy: 0.4979 - val_loss: 1.1621 - val_accuracy: 0.5026\n",
      "Epoch 67/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1800 - accuracy: 0.5046 - val_loss: 1.1612 - val_accuracy: 0.5026\n",
      "Epoch 68/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1848 - accuracy: 0.5015 - val_loss: 1.1605 - val_accuracy: 0.5026\n",
      "Epoch 69/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1797 - accuracy: 0.5018 - val_loss: 1.1598 - val_accuracy: 0.5021\n",
      "Epoch 70/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1838 - accuracy: 0.4981 - val_loss: 1.1589 - val_accuracy: 0.5022\n",
      "Epoch 71/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1798 - accuracy: 0.5039 - val_loss: 1.1582 - val_accuracy: 0.5021\n",
      "Epoch 72/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1771 - accuracy: 0.5029 - val_loss: 1.1577 - val_accuracy: 0.5022\n",
      "Epoch 73/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1808 - accuracy: 0.5008 - val_loss: 1.1569 - val_accuracy: 0.5022\n",
      "Epoch 74/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1740 - accuracy: 0.5040 - val_loss: 1.1562 - val_accuracy: 0.5024\n",
      "Epoch 75/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1775 - accuracy: 0.5021 - val_loss: 1.1554 - val_accuracy: 0.5018\n",
      "Epoch 76/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1776 - accuracy: 0.5021 - val_loss: 1.1549 - val_accuracy: 0.5024\n",
      "Epoch 77/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1727 - accuracy: 0.5029 - val_loss: 1.1543 - val_accuracy: 0.5024\n",
      "Epoch 78/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1726 - accuracy: 0.5059 - val_loss: 1.1537 - val_accuracy: 0.5024\n",
      "Epoch 79/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1706 - accuracy: 0.5031 - val_loss: 1.1531 - val_accuracy: 0.5022\n",
      "Epoch 80/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1724 - accuracy: 0.5032 - val_loss: 1.1526 - val_accuracy: 0.5018\n",
      "Epoch 81/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1689 - accuracy: 0.5063 - val_loss: 1.1518 - val_accuracy: 0.5022\n",
      "Epoch 82/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1672 - accuracy: 0.5095 - val_loss: 1.1514 - val_accuracy: 0.5020\n",
      "Epoch 83/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1701 - accuracy: 0.5054 - val_loss: 1.1509 - val_accuracy: 0.5021\n",
      "Epoch 84/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1714 - accuracy: 0.5050 - val_loss: 1.1503 - val_accuracy: 0.5081\n",
      "Epoch 85/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1662 - accuracy: 0.5061 - val_loss: 1.1499 - val_accuracy: 0.5060\n",
      "Epoch 86/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1678 - accuracy: 0.5038 - val_loss: 1.1493 - val_accuracy: 0.5084\n",
      "Epoch 87/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1640 - accuracy: 0.5082 - val_loss: 1.1486 - val_accuracy: 0.5073\n",
      "Epoch 88/600\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 1.1671 - accuracy: 0.5065 - val_loss: 1.1480 - val_accuracy: 0.5067\n",
      "Epoch 89/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1646 - accuracy: 0.5105 - val_loss: 1.1475 - val_accuracy: 0.5010\n",
      "Epoch 90/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1617 - accuracy: 0.5091 - val_loss: 1.1468 - val_accuracy: 0.5068\n",
      "Epoch 91/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1645 - accuracy: 0.5077 - val_loss: 1.1463 - val_accuracy: 0.5064\n",
      "Epoch 92/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1637 - accuracy: 0.5080 - val_loss: 1.1459 - val_accuracy: 0.5071\n",
      "Epoch 93/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1601 - accuracy: 0.5075 - val_loss: 1.1456 - val_accuracy: 0.5072\n",
      "Epoch 94/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1616 - accuracy: 0.5055 - val_loss: 1.1453 - val_accuracy: 0.5067\n",
      "Epoch 95/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1633 - accuracy: 0.5065 - val_loss: 1.1445 - val_accuracy: 0.5068\n",
      "Epoch 96/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1600 - accuracy: 0.5097 - val_loss: 1.1440 - val_accuracy: 0.5059\n",
      "Epoch 97/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1626 - accuracy: 0.5088 - val_loss: 1.1435 - val_accuracy: 0.5056\n",
      "Epoch 98/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1630 - accuracy: 0.5076 - val_loss: 1.1430 - val_accuracy: 0.5068\n",
      "Epoch 99/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1611 - accuracy: 0.5101 - val_loss: 1.1422 - val_accuracy: 0.5060\n",
      "Epoch 100/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1536 - accuracy: 0.5111 - val_loss: 1.1417 - val_accuracy: 0.5061\n",
      "Epoch 101/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1575 - accuracy: 0.5131 - val_loss: 1.1413 - val_accuracy: 0.5060\n",
      "Epoch 102/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1567 - accuracy: 0.5115 - val_loss: 1.1412 - val_accuracy: 0.5050\n",
      "Epoch 103/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1598 - accuracy: 0.5095 - val_loss: 1.1408 - val_accuracy: 0.5064\n",
      "Epoch 104/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1567 - accuracy: 0.5092 - val_loss: 1.1398 - val_accuracy: 0.5075\n",
      "Epoch 105/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1568 - accuracy: 0.5109 - val_loss: 1.1392 - val_accuracy: 0.5075\n",
      "Epoch 106/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1546 - accuracy: 0.5118 - val_loss: 1.1389 - val_accuracy: 0.5069\n",
      "Epoch 107/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1528 - accuracy: 0.5114 - val_loss: 1.1384 - val_accuracy: 0.5053\n",
      "Epoch 108/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1552 - accuracy: 0.5140 - val_loss: 1.1384 - val_accuracy: 0.5056\n",
      "Epoch 109/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1551 - accuracy: 0.5099 - val_loss: 1.1379 - val_accuracy: 0.5057\n",
      "Epoch 110/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1525 - accuracy: 0.5143 - val_loss: 1.1373 - val_accuracy: 0.5046\n",
      "Epoch 111/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1543 - accuracy: 0.5117 - val_loss: 1.1369 - val_accuracy: 0.5099\n",
      "Epoch 112/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1544 - accuracy: 0.5107 - val_loss: 1.1368 - val_accuracy: 0.5102\n",
      "Epoch 113/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1537 - accuracy: 0.5088 - val_loss: 1.1363 - val_accuracy: 0.5103\n",
      "Epoch 114/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1503 - accuracy: 0.5119 - val_loss: 1.1359 - val_accuracy: 0.5056\n",
      "Epoch 115/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1510 - accuracy: 0.5143 - val_loss: 1.1353 - val_accuracy: 0.5045\n",
      "Epoch 116/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1533 - accuracy: 0.5104 - val_loss: 1.1347 - val_accuracy: 0.5050\n",
      "Epoch 117/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1482 - accuracy: 0.5159 - val_loss: 1.1345 - val_accuracy: 0.5104\n",
      "Epoch 118/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1507 - accuracy: 0.5145 - val_loss: 1.1342 - val_accuracy: 0.5085\n",
      "Epoch 119/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1482 - accuracy: 0.5115 - val_loss: 1.1337 - val_accuracy: 0.5099\n",
      "Epoch 120/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1458 - accuracy: 0.5160 - val_loss: 1.1333 - val_accuracy: 0.5111\n",
      "Epoch 121/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1491 - accuracy: 0.5127 - val_loss: 1.1332 - val_accuracy: 0.5106\n",
      "Epoch 122/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1475 - accuracy: 0.5137 - val_loss: 1.1330 - val_accuracy: 0.5040\n",
      "Epoch 123/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1481 - accuracy: 0.5143 - val_loss: 1.1324 - val_accuracy: 0.5083\n",
      "Epoch 124/600\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1462 - accuracy: 0.5155 - val_loss: 1.1319 - val_accuracy: 0.5111\n",
      "Epoch 125/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1463 - accuracy: 0.5143 - val_loss: 1.1316 - val_accuracy: 0.5115\n",
      "Epoch 126/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1483 - accuracy: 0.5164 - val_loss: 1.1312 - val_accuracy: 0.5084\n",
      "Epoch 127/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1452 - accuracy: 0.5186 - val_loss: 1.1313 - val_accuracy: 0.5077\n",
      "Epoch 128/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1447 - accuracy: 0.5154 - val_loss: 1.1310 - val_accuracy: 0.5063\n",
      "Epoch 129/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1444 - accuracy: 0.5162 - val_loss: 1.1308 - val_accuracy: 0.5045\n",
      "Epoch 130/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1444 - accuracy: 0.5174 - val_loss: 1.1305 - val_accuracy: 0.5049\n",
      "Epoch 131/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1438 - accuracy: 0.5118 - val_loss: 1.1300 - val_accuracy: 0.5107\n",
      "Epoch 132/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1445 - accuracy: 0.5172 - val_loss: 1.1297 - val_accuracy: 0.5119\n",
      "Epoch 133/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1433 - accuracy: 0.5202 - val_loss: 1.1296 - val_accuracy: 0.5111\n",
      "Epoch 134/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1458 - accuracy: 0.5158 - val_loss: 1.1294 - val_accuracy: 0.5102\n",
      "Epoch 135/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1412 - accuracy: 0.5198 - val_loss: 1.1286 - val_accuracy: 0.5096\n",
      "Epoch 136/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1436 - accuracy: 0.5160 - val_loss: 1.1283 - val_accuracy: 0.5095\n",
      "Epoch 137/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1419 - accuracy: 0.5168 - val_loss: 1.1282 - val_accuracy: 0.5084\n",
      "Epoch 138/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1429 - accuracy: 0.5174 - val_loss: 1.1281 - val_accuracy: 0.5085\n",
      "Epoch 139/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1407 - accuracy: 0.5160 - val_loss: 1.1276 - val_accuracy: 0.5106\n",
      "Epoch 140/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1396 - accuracy: 0.5172 - val_loss: 1.1275 - val_accuracy: 0.5099\n",
      "Epoch 141/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1403 - accuracy: 0.5200 - val_loss: 1.1273 - val_accuracy: 0.5100\n",
      "Epoch 142/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1409 - accuracy: 0.5188 - val_loss: 1.1272 - val_accuracy: 0.5100\n",
      "Epoch 143/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1405 - accuracy: 0.5176 - val_loss: 1.1268 - val_accuracy: 0.5094\n",
      "Epoch 144/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1415 - accuracy: 0.5187 - val_loss: 1.1263 - val_accuracy: 0.5096\n",
      "Epoch 145/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1396 - accuracy: 0.5206 - val_loss: 1.1260 - val_accuracy: 0.5098\n",
      "Epoch 146/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1396 - accuracy: 0.5186 - val_loss: 1.1259 - val_accuracy: 0.5099\n",
      "Epoch 147/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1389 - accuracy: 0.5163 - val_loss: 1.1257 - val_accuracy: 0.5099\n",
      "Epoch 148/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1419 - accuracy: 0.5190 - val_loss: 1.1252 - val_accuracy: 0.5094\n",
      "Epoch 149/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1420 - accuracy: 0.5168 - val_loss: 1.1250 - val_accuracy: 0.5111\n",
      "Epoch 150/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1379 - accuracy: 0.5156 - val_loss: 1.1250 - val_accuracy: 0.5107\n",
      "Epoch 151/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1388 - accuracy: 0.5171 - val_loss: 1.1246 - val_accuracy: 0.5094\n",
      "Epoch 152/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1369 - accuracy: 0.5174 - val_loss: 1.1243 - val_accuracy: 0.5095\n",
      "Epoch 153/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1375 - accuracy: 0.5188 - val_loss: 1.1242 - val_accuracy: 0.5059\n",
      "Epoch 154/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1369 - accuracy: 0.5193 - val_loss: 1.1246 - val_accuracy: 0.5102\n",
      "Epoch 155/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1377 - accuracy: 0.5179 - val_loss: 1.1241 - val_accuracy: 0.5081\n",
      "Epoch 156/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1366 - accuracy: 0.5181 - val_loss: 1.1237 - val_accuracy: 0.5079\n",
      "Epoch 157/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1387 - accuracy: 0.5154 - val_loss: 1.1234 - val_accuracy: 0.5055\n",
      "Epoch 158/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1326 - accuracy: 0.5194 - val_loss: 1.1232 - val_accuracy: 0.5072\n",
      "Epoch 159/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1355 - accuracy: 0.5235 - val_loss: 1.1228 - val_accuracy: 0.5060\n",
      "Epoch 160/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1348 - accuracy: 0.5205 - val_loss: 1.1226 - val_accuracy: 0.5069\n",
      "Epoch 161/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1366 - accuracy: 0.5212 - val_loss: 1.1226 - val_accuracy: 0.5069\n",
      "Epoch 162/600\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.1365 - accuracy: 0.5194 - val_loss: 1.1225 - val_accuracy: 0.5085\n",
      "Epoch 163/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1331 - accuracy: 0.5226 - val_loss: 1.1222 - val_accuracy: 0.5098\n",
      "Epoch 164/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1344 - accuracy: 0.5236 - val_loss: 1.1220 - val_accuracy: 0.5111\n",
      "Epoch 165/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1373 - accuracy: 0.5197 - val_loss: 1.1220 - val_accuracy: 0.5099\n",
      "Epoch 166/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1332 - accuracy: 0.5229 - val_loss: 1.1218 - val_accuracy: 0.5096\n",
      "Epoch 167/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1373 - accuracy: 0.5207 - val_loss: 1.1215 - val_accuracy: 0.5123\n",
      "Epoch 168/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1363 - accuracy: 0.5171 - val_loss: 1.1210 - val_accuracy: 0.5141\n",
      "Epoch 169/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1319 - accuracy: 0.5227 - val_loss: 1.1205 - val_accuracy: 0.5103\n",
      "Epoch 170/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1355 - accuracy: 0.5227 - val_loss: 1.1202 - val_accuracy: 0.5102\n",
      "Epoch 171/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1334 - accuracy: 0.5227 - val_loss: 1.1205 - val_accuracy: 0.5137\n",
      "Epoch 172/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1343 - accuracy: 0.5192 - val_loss: 1.1204 - val_accuracy: 0.5094\n",
      "Epoch 173/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1333 - accuracy: 0.5190 - val_loss: 1.1202 - val_accuracy: 0.5091\n",
      "Epoch 174/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1339 - accuracy: 0.5208 - val_loss: 1.1202 - val_accuracy: 0.5091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1305 - accuracy: 0.5229 - val_loss: 1.1200 - val_accuracy: 0.5107\n",
      "Epoch 176/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1323 - accuracy: 0.5221 - val_loss: 1.1197 - val_accuracy: 0.5133\n",
      "Epoch 177/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1349 - accuracy: 0.5211 - val_loss: 1.1198 - val_accuracy: 0.5126\n",
      "Epoch 178/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1333 - accuracy: 0.5209 - val_loss: 1.1192 - val_accuracy: 0.5127\n",
      "Epoch 179/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1301 - accuracy: 0.5227 - val_loss: 1.1188 - val_accuracy: 0.5154\n",
      "Epoch 180/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1339 - accuracy: 0.5217 - val_loss: 1.1188 - val_accuracy: 0.5126\n",
      "Epoch 181/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1338 - accuracy: 0.5187 - val_loss: 1.1189 - val_accuracy: 0.5119\n",
      "Epoch 182/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1313 - accuracy: 0.5217 - val_loss: 1.1186 - val_accuracy: 0.5090\n",
      "Epoch 183/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1349 - accuracy: 0.5193 - val_loss: 1.1186 - val_accuracy: 0.5087\n",
      "Epoch 184/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1352 - accuracy: 0.5223 - val_loss: 1.1185 - val_accuracy: 0.5103\n",
      "Epoch 185/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1326 - accuracy: 0.5202 - val_loss: 1.1180 - val_accuracy: 0.5100\n",
      "Epoch 186/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1323 - accuracy: 0.5237 - val_loss: 1.1178 - val_accuracy: 0.5100\n",
      "Epoch 187/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1300 - accuracy: 0.5221 - val_loss: 1.1176 - val_accuracy: 0.5099\n",
      "Epoch 188/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1325 - accuracy: 0.5197 - val_loss: 1.1177 - val_accuracy: 0.5106\n",
      "Epoch 189/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1314 - accuracy: 0.5211 - val_loss: 1.1177 - val_accuracy: 0.5122\n",
      "Epoch 190/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1303 - accuracy: 0.5246 - val_loss: 1.1172 - val_accuracy: 0.5138\n",
      "Epoch 191/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1329 - accuracy: 0.5218 - val_loss: 1.1170 - val_accuracy: 0.5130\n",
      "Epoch 192/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1309 - accuracy: 0.5231 - val_loss: 1.1170 - val_accuracy: 0.5145\n",
      "Epoch 193/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1295 - accuracy: 0.5237 - val_loss: 1.1172 - val_accuracy: 0.5134\n",
      "Epoch 194/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1312 - accuracy: 0.5235 - val_loss: 1.1165 - val_accuracy: 0.5142\n",
      "Epoch 195/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1288 - accuracy: 0.5231 - val_loss: 1.1161 - val_accuracy: 0.5125\n",
      "Epoch 196/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1274 - accuracy: 0.5257 - val_loss: 1.1160 - val_accuracy: 0.5107\n",
      "Epoch 197/600\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1286 - accuracy: 0.5233 - val_loss: 1.1162 - val_accuracy: 0.5153\n",
      "Epoch 198/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1256 - accuracy: 0.5212 - val_loss: 1.1158 - val_accuracy: 0.5145\n",
      "Epoch 199/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1306 - accuracy: 0.5227 - val_loss: 1.1155 - val_accuracy: 0.5138\n",
      "Epoch 200/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1299 - accuracy: 0.5254 - val_loss: 1.1155 - val_accuracy: 0.5118\n",
      "Epoch 201/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1322 - accuracy: 0.5229 - val_loss: 1.1158 - val_accuracy: 0.5104\n",
      "Epoch 202/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1278 - accuracy: 0.5255 - val_loss: 1.1154 - val_accuracy: 0.5098\n",
      "Epoch 203/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1295 - accuracy: 0.5227 - val_loss: 1.1150 - val_accuracy: 0.5112\n",
      "Epoch 204/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1279 - accuracy: 0.5246 - val_loss: 1.1151 - val_accuracy: 0.5129\n",
      "Epoch 205/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1307 - accuracy: 0.5220 - val_loss: 1.1150 - val_accuracy: 0.5147\n",
      "Epoch 206/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1289 - accuracy: 0.5230 - val_loss: 1.1145 - val_accuracy: 0.5176\n",
      "Epoch 207/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1283 - accuracy: 0.5233 - val_loss: 1.1143 - val_accuracy: 0.5168\n",
      "Epoch 208/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1265 - accuracy: 0.5253 - val_loss: 1.1140 - val_accuracy: 0.5130\n",
      "Epoch 209/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1271 - accuracy: 0.5253 - val_loss: 1.1139 - val_accuracy: 0.5147\n",
      "Epoch 210/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1289 - accuracy: 0.5260 - val_loss: 1.1140 - val_accuracy: 0.5143\n",
      "Epoch 211/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1279 - accuracy: 0.5224 - val_loss: 1.1139 - val_accuracy: 0.5149\n",
      "Epoch 212/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1293 - accuracy: 0.5233 - val_loss: 1.1136 - val_accuracy: 0.5138\n",
      "Epoch 213/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1255 - accuracy: 0.5239 - val_loss: 1.1134 - val_accuracy: 0.5244\n",
      "Epoch 214/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1279 - accuracy: 0.5228 - val_loss: 1.1133 - val_accuracy: 0.5231\n",
      "Epoch 215/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1260 - accuracy: 0.5307 - val_loss: 1.1131 - val_accuracy: 0.5258\n",
      "Epoch 216/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1240 - accuracy: 0.5262 - val_loss: 1.1133 - val_accuracy: 0.5147\n",
      "Epoch 217/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1262 - accuracy: 0.5269 - val_loss: 1.1131 - val_accuracy: 0.5151\n",
      "Epoch 218/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1270 - accuracy: 0.5243 - val_loss: 1.1121 - val_accuracy: 0.5143\n",
      "Epoch 219/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1249 - accuracy: 0.5242 - val_loss: 1.1119 - val_accuracy: 0.5145\n",
      "Epoch 220/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1244 - accuracy: 0.5273 - val_loss: 1.1121 - val_accuracy: 0.5135\n",
      "Epoch 221/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1246 - accuracy: 0.5253 - val_loss: 1.1123 - val_accuracy: 0.5134\n",
      "Epoch 222/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1229 - accuracy: 0.5271 - val_loss: 1.1116 - val_accuracy: 0.5186\n",
      "Epoch 223/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1285 - accuracy: 0.5239 - val_loss: 1.1114 - val_accuracy: 0.5211\n",
      "Epoch 224/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1264 - accuracy: 0.5232 - val_loss: 1.1114 - val_accuracy: 0.5142\n",
      "Epoch 225/600\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1242 - accuracy: 0.5239 - val_loss: 1.1123 - val_accuracy: 0.5153\n",
      "Epoch 226/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1230 - accuracy: 0.5282 - val_loss: 1.1113 - val_accuracy: 0.5141\n",
      "Epoch 227/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1246 - accuracy: 0.5266 - val_loss: 1.1110 - val_accuracy: 0.5312\n",
      "Epoch 228/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1250 - accuracy: 0.5244 - val_loss: 1.1109 - val_accuracy: 0.5151\n",
      "Epoch 229/600\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.1230 - accuracy: 0.5221 - val_loss: 1.1111 - val_accuracy: 0.5151\n",
      "Epoch 230/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1227 - accuracy: 0.5254 - val_loss: 1.1106 - val_accuracy: 0.5176\n",
      "Epoch 231/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1210 - accuracy: 0.5277 - val_loss: 1.1103 - val_accuracy: 0.5174\n",
      "Epoch 232/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1226 - accuracy: 0.5249 - val_loss: 1.1100 - val_accuracy: 0.5164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1256 - accuracy: 0.5259 - val_loss: 1.1097 - val_accuracy: 0.5173\n",
      "Epoch 234/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1216 - accuracy: 0.5269 - val_loss: 1.1096 - val_accuracy: 0.5221\n",
      "Epoch 235/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1213 - accuracy: 0.5314 - val_loss: 1.1096 - val_accuracy: 0.5170\n",
      "Epoch 236/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1226 - accuracy: 0.5251 - val_loss: 1.1097 - val_accuracy: 0.5185\n",
      "Epoch 237/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1184 - accuracy: 0.5291 - val_loss: 1.1091 - val_accuracy: 0.5178\n",
      "Epoch 238/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1231 - accuracy: 0.5277 - val_loss: 1.1086 - val_accuracy: 0.5317\n",
      "Epoch 239/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1240 - accuracy: 0.5285 - val_loss: 1.1087 - val_accuracy: 0.5182\n",
      "Epoch 240/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1241 - accuracy: 0.5253 - val_loss: 1.1087 - val_accuracy: 0.5174\n",
      "Epoch 241/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1200 - accuracy: 0.5300 - val_loss: 1.1086 - val_accuracy: 0.5270\n",
      "Epoch 242/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1244 - accuracy: 0.5246 - val_loss: 1.1084 - val_accuracy: 0.5306\n",
      "Epoch 243/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1170 - accuracy: 0.5280 - val_loss: 1.1084 - val_accuracy: 0.5306\n",
      "Epoch 244/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1218 - accuracy: 0.5258 - val_loss: 1.1084 - val_accuracy: 0.5279\n",
      "Epoch 245/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1215 - accuracy: 0.5279 - val_loss: 1.1084 - val_accuracy: 0.5270\n",
      "Epoch 246/600\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1219 - accuracy: 0.5275 - val_loss: 1.1079 - val_accuracy: 0.5267\n",
      "Epoch 247/600\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1218 - accuracy: 0.5277 - val_loss: 1.1076 - val_accuracy: 0.5318\n",
      "Epoch 248/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1192 - accuracy: 0.5265 - val_loss: 1.1074 - val_accuracy: 0.5316\n",
      "Epoch 249/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1204 - accuracy: 0.5281 - val_loss: 1.1071 - val_accuracy: 0.5317\n",
      "Epoch 250/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1182 - accuracy: 0.5273 - val_loss: 1.1069 - val_accuracy: 0.5322\n",
      "Epoch 251/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1187 - accuracy: 0.5296 - val_loss: 1.1069 - val_accuracy: 0.5293\n",
      "Epoch 252/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1209 - accuracy: 0.5274 - val_loss: 1.1066 - val_accuracy: 0.5281\n",
      "Epoch 253/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1184 - accuracy: 0.5300 - val_loss: 1.1062 - val_accuracy: 0.5325\n",
      "Epoch 254/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1177 - accuracy: 0.5308 - val_loss: 1.1062 - val_accuracy: 0.5330\n",
      "Epoch 255/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1195 - accuracy: 0.5302 - val_loss: 1.1064 - val_accuracy: 0.5282\n",
      "Epoch 256/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1216 - accuracy: 0.5260 - val_loss: 1.1066 - val_accuracy: 0.5189\n",
      "Epoch 257/600\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1202 - accuracy: 0.5260 - val_loss: 1.1066 - val_accuracy: 0.5204\n",
      "Epoch 258/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1192 - accuracy: 0.5286 - val_loss: 1.1062 - val_accuracy: 0.5301\n",
      "Epoch 259/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1175 - accuracy: 0.5311 - val_loss: 1.1058 - val_accuracy: 0.5317\n",
      "Epoch 260/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1164 - accuracy: 0.5314 - val_loss: 1.1060 - val_accuracy: 0.5309\n",
      "Epoch 261/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1197 - accuracy: 0.5301 - val_loss: 1.1061 - val_accuracy: 0.5265\n",
      "Epoch 262/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1212 - accuracy: 0.5280 - val_loss: 1.1056 - val_accuracy: 0.5326\n",
      "Epoch 263/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1161 - accuracy: 0.5310 - val_loss: 1.1054 - val_accuracy: 0.5324\n",
      "Epoch 264/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1178 - accuracy: 0.5294 - val_loss: 1.1055 - val_accuracy: 0.5301\n",
      "Epoch 265/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1189 - accuracy: 0.5283 - val_loss: 1.1055 - val_accuracy: 0.5297\n",
      "Epoch 266/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1204 - accuracy: 0.5263 - val_loss: 1.1050 - val_accuracy: 0.5305\n",
      "Epoch 267/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1177 - accuracy: 0.5312 - val_loss: 1.1049 - val_accuracy: 0.5301\n",
      "Epoch 268/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1174 - accuracy: 0.5298 - val_loss: 1.1049 - val_accuracy: 0.5314\n",
      "Epoch 269/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1204 - accuracy: 0.5287 - val_loss: 1.1049 - val_accuracy: 0.5286\n",
      "Epoch 270/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1191 - accuracy: 0.5266 - val_loss: 1.1044 - val_accuracy: 0.5305\n",
      "Epoch 271/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1170 - accuracy: 0.5315 - val_loss: 1.1041 - val_accuracy: 0.5332\n",
      "Epoch 272/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1207 - accuracy: 0.5294 - val_loss: 1.1042 - val_accuracy: 0.5308\n",
      "Epoch 273/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1151 - accuracy: 0.5328 - val_loss: 1.1041 - val_accuracy: 0.5294\n",
      "Epoch 274/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1174 - accuracy: 0.5314 - val_loss: 1.1040 - val_accuracy: 0.5302\n",
      "Epoch 275/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1179 - accuracy: 0.5289 - val_loss: 1.1037 - val_accuracy: 0.5305\n",
      "Epoch 276/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1138 - accuracy: 0.5290 - val_loss: 1.1035 - val_accuracy: 0.5305\n",
      "Epoch 277/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1163 - accuracy: 0.5291 - val_loss: 1.1032 - val_accuracy: 0.5316\n",
      "Epoch 278/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1139 - accuracy: 0.5320 - val_loss: 1.1032 - val_accuracy: 0.5314\n",
      "Epoch 279/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1169 - accuracy: 0.5294 - val_loss: 1.1032 - val_accuracy: 0.5313\n",
      "Epoch 280/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1180 - accuracy: 0.5275 - val_loss: 1.1032 - val_accuracy: 0.5316\n",
      "Epoch 281/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1171 - accuracy: 0.5285 - val_loss: 1.1030 - val_accuracy: 0.5325\n",
      "Epoch 282/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1154 - accuracy: 0.5326 - val_loss: 1.1029 - val_accuracy: 0.5316\n",
      "Epoch 283/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1124 - accuracy: 0.5307 - val_loss: 1.1026 - val_accuracy: 0.5341\n",
      "Epoch 284/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1143 - accuracy: 0.5288 - val_loss: 1.1024 - val_accuracy: 0.5328\n",
      "Epoch 285/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1168 - accuracy: 0.5335 - val_loss: 1.1024 - val_accuracy: 0.5325\n",
      "Epoch 286/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1167 - accuracy: 0.5314 - val_loss: 1.1023 - val_accuracy: 0.5345\n",
      "Epoch 287/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1132 - accuracy: 0.5350 - val_loss: 1.1021 - val_accuracy: 0.5347\n",
      "Epoch 288/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1158 - accuracy: 0.5315 - val_loss: 1.1022 - val_accuracy: 0.5332\n",
      "Epoch 289/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1137 - accuracy: 0.5316 - val_loss: 1.1021 - val_accuracy: 0.5314\n",
      "Epoch 290/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1182 - accuracy: 0.5252 - val_loss: 1.1019 - val_accuracy: 0.5317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1145 - accuracy: 0.5304 - val_loss: 1.1018 - val_accuracy: 0.5308\n",
      "Epoch 292/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1151 - accuracy: 0.5307 - val_loss: 1.1015 - val_accuracy: 0.5341\n",
      "Epoch 293/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1139 - accuracy: 0.5308 - val_loss: 1.1014 - val_accuracy: 0.5357\n",
      "Epoch 294/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1149 - accuracy: 0.5298 - val_loss: 1.1013 - val_accuracy: 0.5349\n",
      "Epoch 295/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1117 - accuracy: 0.5348 - val_loss: 1.1014 - val_accuracy: 0.5335\n",
      "Epoch 296/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1121 - accuracy: 0.5337 - val_loss: 1.1014 - val_accuracy: 0.5336\n",
      "Epoch 297/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1148 - accuracy: 0.5327 - val_loss: 1.1013 - val_accuracy: 0.5339\n",
      "Epoch 298/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1150 - accuracy: 0.5300 - val_loss: 1.1010 - val_accuracy: 0.5345\n",
      "Epoch 299/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1113 - accuracy: 0.5316 - val_loss: 1.1008 - val_accuracy: 0.5355\n",
      "Epoch 300/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1123 - accuracy: 0.5364 - val_loss: 1.1007 - val_accuracy: 0.5351\n",
      "Epoch 301/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1129 - accuracy: 0.5355 - val_loss: 1.1005 - val_accuracy: 0.5340\n",
      "Epoch 302/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1135 - accuracy: 0.5324 - val_loss: 1.1008 - val_accuracy: 0.5301\n",
      "Epoch 303/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1127 - accuracy: 0.5305 - val_loss: 1.1006 - val_accuracy: 0.5300\n",
      "Epoch 304/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1126 - accuracy: 0.5323 - val_loss: 1.1006 - val_accuracy: 0.5328\n",
      "Epoch 305/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1146 - accuracy: 0.5322 - val_loss: 1.1008 - val_accuracy: 0.5328\n",
      "Epoch 306/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1161 - accuracy: 0.5307 - val_loss: 1.1005 - val_accuracy: 0.5361\n",
      "Epoch 307/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1139 - accuracy: 0.5334 - val_loss: 1.1003 - val_accuracy: 0.5349\n",
      "Epoch 308/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1122 - accuracy: 0.5335 - val_loss: 1.1002 - val_accuracy: 0.5340\n",
      "Epoch 309/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1147 - accuracy: 0.5305 - val_loss: 1.1000 - val_accuracy: 0.5317\n",
      "Epoch 310/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1117 - accuracy: 0.5322 - val_loss: 1.0996 - val_accuracy: 0.5312\n",
      "Epoch 311/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1138 - accuracy: 0.5356 - val_loss: 1.0994 - val_accuracy: 0.5310\n",
      "Epoch 312/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1115 - accuracy: 0.5300 - val_loss: 1.0991 - val_accuracy: 0.5336\n",
      "Epoch 313/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1109 - accuracy: 0.5325 - val_loss: 1.0991 - val_accuracy: 0.5353\n",
      "Epoch 314/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1132 - accuracy: 0.5327 - val_loss: 1.0994 - val_accuracy: 0.5357\n",
      "Epoch 315/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1124 - accuracy: 0.5324 - val_loss: 1.0996 - val_accuracy: 0.5345\n",
      "Epoch 316/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1121 - accuracy: 0.5339 - val_loss: 1.0996 - val_accuracy: 0.5324\n",
      "Epoch 317/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1127 - accuracy: 0.5317 - val_loss: 1.0994 - val_accuracy: 0.5332\n",
      "Epoch 318/600\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.1110 - accuracy: 0.5332 - val_loss: 1.0991 - val_accuracy: 0.5347\n",
      "Epoch 319/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1144 - accuracy: 0.5324 - val_loss: 1.0988 - val_accuracy: 0.5348\n",
      "Epoch 320/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1116 - accuracy: 0.5339 - val_loss: 1.0987 - val_accuracy: 0.5351\n",
      "Epoch 321/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1088 - accuracy: 0.5355 - val_loss: 1.0983 - val_accuracy: 0.5367\n",
      "Epoch 322/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1128 - accuracy: 0.5345 - val_loss: 1.0982 - val_accuracy: 0.5349\n",
      "Epoch 323/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1105 - accuracy: 0.5322 - val_loss: 1.0983 - val_accuracy: 0.5347\n",
      "Epoch 324/600\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.1122 - accuracy: 0.5358 - val_loss: 1.0980 - val_accuracy: 0.5356\n",
      "Epoch 325/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1102 - accuracy: 0.5378 - val_loss: 1.0980 - val_accuracy: 0.5394\n",
      "Epoch 326/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1125 - accuracy: 0.5356 - val_loss: 1.0982 - val_accuracy: 0.5344\n",
      "Epoch 327/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1123 - accuracy: 0.5315 - val_loss: 1.0981 - val_accuracy: 0.5325\n",
      "Epoch 328/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1105 - accuracy: 0.5322 - val_loss: 1.0979 - val_accuracy: 0.5361\n",
      "Epoch 329/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1122 - accuracy: 0.5334 - val_loss: 1.0981 - val_accuracy: 0.5349\n",
      "Epoch 330/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1097 - accuracy: 0.5337 - val_loss: 1.0983 - val_accuracy: 0.5357\n",
      "Epoch 331/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1088 - accuracy: 0.5328 - val_loss: 1.0982 - val_accuracy: 0.5345\n",
      "Epoch 332/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1090 - accuracy: 0.5341 - val_loss: 1.0979 - val_accuracy: 0.5339\n",
      "Epoch 333/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1100 - accuracy: 0.5340 - val_loss: 1.0978 - val_accuracy: 0.5328\n",
      "Epoch 334/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1104 - accuracy: 0.5361 - val_loss: 1.0975 - val_accuracy: 0.5329\n",
      "Epoch 335/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1084 - accuracy: 0.5339 - val_loss: 1.0974 - val_accuracy: 0.5336\n",
      "Epoch 336/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1101 - accuracy: 0.5329 - val_loss: 1.0973 - val_accuracy: 0.5339\n",
      "Epoch 337/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1115 - accuracy: 0.5306 - val_loss: 1.0970 - val_accuracy: 0.5341\n",
      "Epoch 338/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1096 - accuracy: 0.5340 - val_loss: 1.0969 - val_accuracy: 0.5351\n",
      "Epoch 339/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1141 - accuracy: 0.5339 - val_loss: 1.0975 - val_accuracy: 0.5339\n",
      "Epoch 340/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1113 - accuracy: 0.5325 - val_loss: 1.0975 - val_accuracy: 0.5369\n",
      "Epoch 341/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1110 - accuracy: 0.5343 - val_loss: 1.0975 - val_accuracy: 0.5364\n",
      "Epoch 342/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1108 - accuracy: 0.5360 - val_loss: 1.0973 - val_accuracy: 0.5374\n",
      "Epoch 343/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1120 - accuracy: 0.5337 - val_loss: 1.0969 - val_accuracy: 0.5332\n",
      "Epoch 344/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1120 - accuracy: 0.5367 - val_loss: 1.0970 - val_accuracy: 0.5322\n",
      "Epoch 345/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1116 - accuracy: 0.5354 - val_loss: 1.0970 - val_accuracy: 0.5322\n",
      "Epoch 346/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1086 - accuracy: 0.5325 - val_loss: 1.0965 - val_accuracy: 0.5363\n",
      "Epoch 347/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1069 - accuracy: 0.5393 - val_loss: 1.0966 - val_accuracy: 0.5372\n",
      "Epoch 348/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1070 - accuracy: 0.5353 - val_loss: 1.0967 - val_accuracy: 0.5339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1108 - accuracy: 0.5327 - val_loss: 1.0971 - val_accuracy: 0.5335\n",
      "Epoch 350/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1108 - accuracy: 0.5375 - val_loss: 1.0966 - val_accuracy: 0.5326\n",
      "Epoch 351/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1112 - accuracy: 0.5309 - val_loss: 1.0963 - val_accuracy: 0.5349\n",
      "Epoch 352/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1089 - accuracy: 0.5355 - val_loss: 1.0964 - val_accuracy: 0.5363\n",
      "Epoch 353/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1100 - accuracy: 0.5331 - val_loss: 1.0962 - val_accuracy: 0.5360\n",
      "Epoch 354/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1081 - accuracy: 0.5324 - val_loss: 1.0963 - val_accuracy: 0.5395\n",
      "Epoch 355/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1052 - accuracy: 0.5342 - val_loss: 1.0962 - val_accuracy: 0.5365\n",
      "Epoch 356/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1109 - accuracy: 0.5322 - val_loss: 1.0964 - val_accuracy: 0.5335\n",
      "Epoch 357/600\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1096 - accuracy: 0.5354 - val_loss: 1.0961 - val_accuracy: 0.5341\n",
      "Epoch 358/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1074 - accuracy: 0.5369 - val_loss: 1.0956 - val_accuracy: 0.5365\n",
      "Epoch 359/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1069 - accuracy: 0.5379 - val_loss: 1.0958 - val_accuracy: 0.5335\n",
      "Epoch 360/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1098 - accuracy: 0.5338 - val_loss: 1.0957 - val_accuracy: 0.5332\n",
      "Epoch 361/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1091 - accuracy: 0.5344 - val_loss: 1.0955 - val_accuracy: 0.5344\n",
      "Epoch 362/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1088 - accuracy: 0.5361 - val_loss: 1.0954 - val_accuracy: 0.5353\n",
      "Epoch 363/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1074 - accuracy: 0.5339 - val_loss: 1.0956 - val_accuracy: 0.5357\n",
      "Epoch 364/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1084 - accuracy: 0.5347 - val_loss: 1.0959 - val_accuracy: 0.5343\n",
      "Epoch 365/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1052 - accuracy: 0.5346 - val_loss: 1.0958 - val_accuracy: 0.5341\n",
      "Epoch 366/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1070 - accuracy: 0.5369 - val_loss: 1.0952 - val_accuracy: 0.5348\n",
      "Epoch 367/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1085 - accuracy: 0.5377 - val_loss: 1.0951 - val_accuracy: 0.5360\n",
      "Epoch 368/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1060 - accuracy: 0.5376 - val_loss: 1.0953 - val_accuracy: 0.5326\n",
      "Epoch 369/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1084 - accuracy: 0.5367 - val_loss: 1.0953 - val_accuracy: 0.5347\n",
      "Epoch 370/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1050 - accuracy: 0.5360 - val_loss: 1.0950 - val_accuracy: 0.5400\n",
      "Epoch 371/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1090 - accuracy: 0.5341 - val_loss: 1.0946 - val_accuracy: 0.5400\n",
      "Epoch 372/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1080 - accuracy: 0.5349 - val_loss: 1.0944 - val_accuracy: 0.5384\n",
      "Epoch 373/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1067 - accuracy: 0.5361 - val_loss: 1.0945 - val_accuracy: 0.5379\n",
      "Epoch 374/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1087 - accuracy: 0.5316 - val_loss: 1.0942 - val_accuracy: 0.5361\n",
      "Epoch 375/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1050 - accuracy: 0.5381 - val_loss: 1.0943 - val_accuracy: 0.5337\n",
      "Epoch 376/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1040 - accuracy: 0.5373 - val_loss: 1.0947 - val_accuracy: 0.5335\n",
      "Epoch 377/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1046 - accuracy: 0.5362 - val_loss: 1.0945 - val_accuracy: 0.5361\n",
      "Epoch 378/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1074 - accuracy: 0.5388 - val_loss: 1.0945 - val_accuracy: 0.5352\n",
      "Epoch 379/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1090 - accuracy: 0.5345 - val_loss: 1.0948 - val_accuracy: 0.5330\n",
      "Epoch 380/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1071 - accuracy: 0.5349 - val_loss: 1.0941 - val_accuracy: 0.5325\n",
      "Epoch 381/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1069 - accuracy: 0.5345 - val_loss: 1.0935 - val_accuracy: 0.5386\n",
      "Epoch 382/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1041 - accuracy: 0.5365 - val_loss: 1.0935 - val_accuracy: 0.5396\n",
      "Epoch 383/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1087 - accuracy: 0.5365 - val_loss: 1.0939 - val_accuracy: 0.5348\n",
      "Epoch 384/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1080 - accuracy: 0.5365 - val_loss: 1.0942 - val_accuracy: 0.5343\n",
      "Epoch 385/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1050 - accuracy: 0.5351 - val_loss: 1.0941 - val_accuracy: 0.5351\n",
      "Epoch 386/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1095 - accuracy: 0.5369 - val_loss: 1.0937 - val_accuracy: 0.5375\n",
      "Epoch 387/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1046 - accuracy: 0.5373 - val_loss: 1.0937 - val_accuracy: 0.5360\n",
      "Epoch 388/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1047 - accuracy: 0.5387 - val_loss: 1.0937 - val_accuracy: 0.5349\n",
      "Epoch 389/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1089 - accuracy: 0.5332 - val_loss: 1.0936 - val_accuracy: 0.5335\n",
      "Epoch 390/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1055 - accuracy: 0.5357 - val_loss: 1.0934 - val_accuracy: 0.5332\n",
      "Epoch 391/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1063 - accuracy: 0.5354 - val_loss: 1.0932 - val_accuracy: 0.5335\n",
      "Epoch 392/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1036 - accuracy: 0.5389 - val_loss: 1.0932 - val_accuracy: 0.5345\n",
      "Epoch 393/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1038 - accuracy: 0.5389 - val_loss: 1.0931 - val_accuracy: 0.5345\n",
      "Epoch 394/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1068 - accuracy: 0.5368 - val_loss: 1.0931 - val_accuracy: 0.5357\n",
      "Epoch 395/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1075 - accuracy: 0.5343 - val_loss: 1.0932 - val_accuracy: 0.5341\n",
      "Epoch 396/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1044 - accuracy: 0.5362 - val_loss: 1.0930 - val_accuracy: 0.5360\n",
      "Epoch 397/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1058 - accuracy: 0.5398 - val_loss: 1.0928 - val_accuracy: 0.5363\n",
      "Epoch 398/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1035 - accuracy: 0.5376 - val_loss: 1.0925 - val_accuracy: 0.5372\n",
      "Epoch 399/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1055 - accuracy: 0.5381 - val_loss: 1.0923 - val_accuracy: 0.5421\n",
      "Epoch 400/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1032 - accuracy: 0.5402 - val_loss: 1.0925 - val_accuracy: 0.5351\n",
      "Epoch 401/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1054 - accuracy: 0.5350 - val_loss: 1.0929 - val_accuracy: 0.5352\n",
      "Epoch 402/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1040 - accuracy: 0.5357 - val_loss: 1.0927 - val_accuracy: 0.5361\n",
      "Epoch 403/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1076 - accuracy: 0.5360 - val_loss: 1.0927 - val_accuracy: 0.5368\n",
      "Epoch 404/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1090 - accuracy: 0.5338 - val_loss: 1.0927 - val_accuracy: 0.5352\n",
      "Epoch 405/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1051 - accuracy: 0.5361 - val_loss: 1.0923 - val_accuracy: 0.5341\n",
      "Epoch 406/600\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1058 - accuracy: 0.5385 - val_loss: 1.0919 - val_accuracy: 0.5383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1074 - accuracy: 0.5355 - val_loss: 1.0921 - val_accuracy: 0.5349\n",
      "Epoch 408/600\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.1052 - accuracy: 0.5356 - val_loss: 1.0926 - val_accuracy: 0.5355\n",
      "Epoch 409/600\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.1026 - accuracy: 0.5379 - val_loss: 1.0927 - val_accuracy: 0.5388\n",
      "Epoch 410/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1072 - accuracy: 0.5394 - val_loss: 1.0924 - val_accuracy: 0.5395\n",
      "Epoch 411/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1018 - accuracy: 0.5425 - val_loss: 1.0916 - val_accuracy: 0.5391\n",
      "Epoch 412/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1055 - accuracy: 0.5376 - val_loss: 1.0914 - val_accuracy: 0.5369\n",
      "Epoch 413/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1046 - accuracy: 0.5375 - val_loss: 1.0912 - val_accuracy: 0.5369\n",
      "Epoch 414/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1047 - accuracy: 0.5382 - val_loss: 1.0910 - val_accuracy: 0.5439\n",
      "Epoch 415/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1034 - accuracy: 0.5414 - val_loss: 1.0914 - val_accuracy: 0.5367\n",
      "Epoch 416/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1036 - accuracy: 0.5359 - val_loss: 1.0912 - val_accuracy: 0.5369\n",
      "Epoch 417/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1063 - accuracy: 0.5372 - val_loss: 1.0913 - val_accuracy: 0.5383\n",
      "Epoch 418/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1048 - accuracy: 0.5374 - val_loss: 1.0916 - val_accuracy: 0.5372\n",
      "Epoch 419/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1025 - accuracy: 0.5396 - val_loss: 1.0916 - val_accuracy: 0.5378\n",
      "Epoch 420/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1030 - accuracy: 0.5372 - val_loss: 1.0913 - val_accuracy: 0.5430\n",
      "Epoch 421/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1043 - accuracy: 0.5351 - val_loss: 1.0912 - val_accuracy: 0.5382\n",
      "Epoch 422/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1045 - accuracy: 0.5377 - val_loss: 1.0913 - val_accuracy: 0.5360\n",
      "Epoch 423/600\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.1032 - accuracy: 0.5331 - val_loss: 1.0906 - val_accuracy: 0.5400\n",
      "Epoch 424/600\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.1050 - accuracy: 0.5385 - val_loss: 1.0903 - val_accuracy: 0.5435\n",
      "Epoch 425/600\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.1026 - accuracy: 0.5359 - val_loss: 1.0908 - val_accuracy: 0.5341\n",
      "Epoch 426/600\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.1039 - accuracy: 0.5389 - val_loss: 1.0909 - val_accuracy: 0.5343\n",
      "Epoch 427/600\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.1016 - accuracy: 0.5376 - val_loss: 1.0907 - val_accuracy: 0.5434\n",
      "Epoch 428/600\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.1061 - accuracy: 0.5354 - val_loss: 1.0910 - val_accuracy: 0.5399\n",
      "Epoch 429/600\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.1050 - accuracy: 0.5393 - val_loss: 1.0912 - val_accuracy: 0.5392\n",
      "Epoch 430/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.1039 - accuracy: 0.5399 - val_loss: 1.0915 - val_accuracy: 0.5364\n",
      "Epoch 431/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1024 - accuracy: 0.5382 - val_loss: 1.0907 - val_accuracy: 0.5372\n",
      "Epoch 432/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1025 - accuracy: 0.5371 - val_loss: 1.0901 - val_accuracy: 0.5444\n",
      "Epoch 433/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1054 - accuracy: 0.5372 - val_loss: 1.0902 - val_accuracy: 0.5341\n",
      "Epoch 434/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1043 - accuracy: 0.5349 - val_loss: 1.0902 - val_accuracy: 0.5341\n",
      "Epoch 435/600\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.1056 - accuracy: 0.5379 - val_loss: 1.0903 - val_accuracy: 0.5404\n",
      "Epoch 436/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1045 - accuracy: 0.5364 - val_loss: 1.0904 - val_accuracy: 0.5407\n",
      "Epoch 437/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1031 - accuracy: 0.5382 - val_loss: 1.0903 - val_accuracy: 0.5355\n",
      "Epoch 438/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0994 - accuracy: 0.5395 - val_loss: 1.0900 - val_accuracy: 0.5434\n",
      "Epoch 439/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1016 - accuracy: 0.5412 - val_loss: 1.0897 - val_accuracy: 0.5466\n",
      "Epoch 440/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1015 - accuracy: 0.5402 - val_loss: 1.0898 - val_accuracy: 0.5406\n",
      "Epoch 441/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1013 - accuracy: 0.5381 - val_loss: 1.0901 - val_accuracy: 0.5378\n",
      "Epoch 442/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1019 - accuracy: 0.5390 - val_loss: 1.0901 - val_accuracy: 0.5423\n",
      "Epoch 443/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1068 - accuracy: 0.5358 - val_loss: 1.0901 - val_accuracy: 0.5441\n",
      "Epoch 444/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0999 - accuracy: 0.5401 - val_loss: 1.0899 - val_accuracy: 0.5403\n",
      "Epoch 445/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1056 - accuracy: 0.5343 - val_loss: 1.0900 - val_accuracy: 0.5357\n",
      "Epoch 446/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1021 - accuracy: 0.5396 - val_loss: 1.0897 - val_accuracy: 0.5380\n",
      "Epoch 447/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0998 - accuracy: 0.5429 - val_loss: 1.0896 - val_accuracy: 0.5434\n",
      "Epoch 448/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1031 - accuracy: 0.5373 - val_loss: 1.0896 - val_accuracy: 0.5380\n",
      "Epoch 449/600\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.1040 - accuracy: 0.5341 - val_loss: 1.0894 - val_accuracy: 0.5392\n",
      "Epoch 450/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0979 - accuracy: 0.5386 - val_loss: 1.0892 - val_accuracy: 0.5411\n",
      "Epoch 451/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1026 - accuracy: 0.5365 - val_loss: 1.0894 - val_accuracy: 0.5437\n",
      "Epoch 452/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1044 - accuracy: 0.5375 - val_loss: 1.0896 - val_accuracy: 0.5357\n",
      "Epoch 453/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1017 - accuracy: 0.5387 - val_loss: 1.0895 - val_accuracy: 0.5402\n",
      "Epoch 454/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1030 - accuracy: 0.5385 - val_loss: 1.0894 - val_accuracy: 0.5457\n",
      "Epoch 455/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1032 - accuracy: 0.5398 - val_loss: 1.0895 - val_accuracy: 0.5407\n",
      "Epoch 456/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1020 - accuracy: 0.5420 - val_loss: 1.0894 - val_accuracy: 0.5413\n",
      "Epoch 457/600\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.1005 - accuracy: 0.5377 - val_loss: 1.0893 - val_accuracy: 0.5446\n",
      "Epoch 458/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0994 - accuracy: 0.5384 - val_loss: 1.0891 - val_accuracy: 0.5445\n",
      "Epoch 459/600\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1004 - accuracy: 0.5375 - val_loss: 1.0890 - val_accuracy: 0.5426\n",
      "Epoch 460/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1034 - accuracy: 0.5377 - val_loss: 1.0893 - val_accuracy: 0.5387\n",
      "Epoch 461/600\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.1042 - accuracy: 0.5356 - val_loss: 1.0891 - val_accuracy: 0.5395\n",
      "Epoch 462/600\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.1011 - accuracy: 0.5387 - val_loss: 1.0888 - val_accuracy: 0.5456\n",
      "Epoch 463/600\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.1030 - accuracy: 0.5391 - val_loss: 1.0888 - val_accuracy: 0.5434\n",
      "Epoch 464/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1024 - accuracy: 0.5407 - val_loss: 1.0887 - val_accuracy: 0.5394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/600\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.1032 - accuracy: 0.5380 - val_loss: 1.0882 - val_accuracy: 0.5407\n",
      "Epoch 466/600\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.1006 - accuracy: 0.5381 - val_loss: 1.0882 - val_accuracy: 0.5407\n",
      "Epoch 467/600\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.1017 - accuracy: 0.5382 - val_loss: 1.0881 - val_accuracy: 0.5468\n",
      "Epoch 468/600\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.1037 - accuracy: 0.5392 - val_loss: 1.0885 - val_accuracy: 0.5452\n",
      "Epoch 469/600\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.1010 - accuracy: 0.5397 - val_loss: 1.0892 - val_accuracy: 0.5367\n",
      "Epoch 470/600\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.0991 - accuracy: 0.5381 - val_loss: 1.0891 - val_accuracy: 0.5413\n",
      "Epoch 471/600\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1016 - accuracy: 0.5417 - val_loss: 1.0887 - val_accuracy: 0.5396\n",
      "Epoch 472/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1015 - accuracy: 0.5378 - val_loss: 1.0884 - val_accuracy: 0.5410\n",
      "Epoch 473/600\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.1049 - accuracy: 0.5347 - val_loss: 1.0881 - val_accuracy: 0.5437\n",
      "Epoch 474/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1006 - accuracy: 0.5390 - val_loss: 1.0880 - val_accuracy: 0.5429\n",
      "Epoch 475/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1007 - accuracy: 0.5414 - val_loss: 1.0878 - val_accuracy: 0.5413\n",
      "Epoch 476/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1005 - accuracy: 0.5387 - val_loss: 1.0878 - val_accuracy: 0.5431\n",
      "Epoch 477/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1015 - accuracy: 0.5413 - val_loss: 1.0878 - val_accuracy: 0.5437\n",
      "Epoch 478/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1019 - accuracy: 0.5408 - val_loss: 1.0877 - val_accuracy: 0.5458\n",
      "Epoch 479/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1001 - accuracy: 0.5403 - val_loss: 1.0875 - val_accuracy: 0.5480\n",
      "Epoch 480/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1018 - accuracy: 0.5383 - val_loss: 1.0876 - val_accuracy: 0.5387\n",
      "Epoch 481/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1003 - accuracy: 0.5390 - val_loss: 1.0878 - val_accuracy: 0.5380\n",
      "Epoch 482/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1017 - accuracy: 0.5402 - val_loss: 1.0879 - val_accuracy: 0.5427\n",
      "Epoch 483/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1041 - accuracy: 0.5408 - val_loss: 1.0881 - val_accuracy: 0.5403\n",
      "Epoch 484/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1012 - accuracy: 0.5409 - val_loss: 1.0879 - val_accuracy: 0.5410\n",
      "Epoch 485/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1002 - accuracy: 0.5395 - val_loss: 1.0873 - val_accuracy: 0.5460\n",
      "Epoch 486/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0990 - accuracy: 0.5386 - val_loss: 1.0867 - val_accuracy: 0.5441\n",
      "Epoch 487/600\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0991 - accuracy: 0.5398 - val_loss: 1.0863 - val_accuracy: 0.5407\n",
      "Epoch 488/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0967 - accuracy: 0.5371 - val_loss: 1.0862 - val_accuracy: 0.5425\n",
      "Epoch 489/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1000 - accuracy: 0.5406 - val_loss: 1.0860 - val_accuracy: 0.5474\n",
      "Epoch 490/600\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.0985 - accuracy: 0.5434 - val_loss: 1.0862 - val_accuracy: 0.5452\n",
      "Epoch 491/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0998 - accuracy: 0.5368 - val_loss: 1.0867 - val_accuracy: 0.5376\n",
      "Epoch 492/600\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0966 - accuracy: 0.5422 - val_loss: 1.0867 - val_accuracy: 0.5454\n",
      "Epoch 493/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.0977 - accuracy: 0.5429 - val_loss: 1.0867 - val_accuracy: 0.5480\n",
      "Epoch 494/600\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0999 - accuracy: 0.5409 - val_loss: 1.0870 - val_accuracy: 0.5425\n",
      "Epoch 495/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0975 - accuracy: 0.5429 - val_loss: 1.0869 - val_accuracy: 0.5415\n",
      "Epoch 496/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1010 - accuracy: 0.5408 - val_loss: 1.0863 - val_accuracy: 0.5422\n",
      "Epoch 497/600\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.0972 - accuracy: 0.5406 - val_loss: 1.0861 - val_accuracy: 0.5461\n",
      "Epoch 498/600\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.0984 - accuracy: 0.5406 - val_loss: 1.0860 - val_accuracy: 0.5423\n",
      "Epoch 499/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0980 - accuracy: 0.5401 - val_loss: 1.0859 - val_accuracy: 0.5433\n",
      "Epoch 500/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0985 - accuracy: 0.5400 - val_loss: 1.0861 - val_accuracy: 0.5435\n",
      "Epoch 501/600\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.0978 - accuracy: 0.5423 - val_loss: 1.0864 - val_accuracy: 0.5388\n",
      "Epoch 502/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1040 - accuracy: 0.5378 - val_loss: 1.0860 - val_accuracy: 0.5460\n",
      "Epoch 503/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1017 - accuracy: 0.5366 - val_loss: 1.0859 - val_accuracy: 0.5461\n",
      "Epoch 504/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0991 - accuracy: 0.5378 - val_loss: 1.0861 - val_accuracy: 0.5452\n",
      "Epoch 505/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0947 - accuracy: 0.5416 - val_loss: 1.0862 - val_accuracy: 0.5437\n",
      "Epoch 506/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.0988 - accuracy: 0.5392 - val_loss: 1.0864 - val_accuracy: 0.5437\n",
      "Epoch 507/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0982 - accuracy: 0.5366 - val_loss: 1.0859 - val_accuracy: 0.5457\n",
      "Epoch 508/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0967 - accuracy: 0.5421 - val_loss: 1.0853 - val_accuracy: 0.5489\n",
      "Epoch 509/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0978 - accuracy: 0.5435 - val_loss: 1.0853 - val_accuracy: 0.5468\n",
      "Epoch 510/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1004 - accuracy: 0.5416 - val_loss: 1.0854 - val_accuracy: 0.5437\n",
      "Epoch 511/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0968 - accuracy: 0.5439 - val_loss: 1.0849 - val_accuracy: 0.5472\n",
      "Epoch 512/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1019 - accuracy: 0.5396 - val_loss: 1.0847 - val_accuracy: 0.5473\n",
      "Epoch 513/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1013 - accuracy: 0.5434 - val_loss: 1.0849 - val_accuracy: 0.5433\n",
      "Epoch 514/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.0959 - accuracy: 0.5422 - val_loss: 1.0850 - val_accuracy: 0.5422\n",
      "Epoch 515/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0976 - accuracy: 0.5450 - val_loss: 1.0846 - val_accuracy: 0.5470\n",
      "Epoch 516/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1022 - accuracy: 0.5410 - val_loss: 1.0848 - val_accuracy: 0.5452\n",
      "Epoch 517/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0990 - accuracy: 0.5359 - val_loss: 1.0854 - val_accuracy: 0.5425\n",
      "Epoch 518/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.0998 - accuracy: 0.5416 - val_loss: 1.0849 - val_accuracy: 0.5491\n",
      "Epoch 519/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0972 - accuracy: 0.5421 - val_loss: 1.0848 - val_accuracy: 0.5445\n",
      "Epoch 520/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0978 - accuracy: 0.5394 - val_loss: 1.0855 - val_accuracy: 0.5410\n",
      "Epoch 521/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.0983 - accuracy: 0.5412 - val_loss: 1.0851 - val_accuracy: 0.5461\n",
      "Epoch 522/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0992 - accuracy: 0.5429 - val_loss: 1.0851 - val_accuracy: 0.5423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.0949 - accuracy: 0.5422 - val_loss: 1.0850 - val_accuracy: 0.5444\n",
      "Epoch 524/600\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.0953 - accuracy: 0.5440 - val_loss: 1.0847 - val_accuracy: 0.5466\n",
      "Epoch 525/600\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.0937 - accuracy: 0.5459 - val_loss: 1.0846 - val_accuracy: 0.5472\n",
      "Epoch 526/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0975 - accuracy: 0.5413 - val_loss: 1.0846 - val_accuracy: 0.5439\n",
      "Epoch 527/600\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.0979 - accuracy: 0.5412 - val_loss: 1.0843 - val_accuracy: 0.5453\n",
      "Epoch 528/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0985 - accuracy: 0.5416 - val_loss: 1.0842 - val_accuracy: 0.5458\n",
      "Epoch 529/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0956 - accuracy: 0.5396 - val_loss: 1.0844 - val_accuracy: 0.5423\n",
      "Epoch 530/600\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.0967 - accuracy: 0.5402 - val_loss: 1.0842 - val_accuracy: 0.5449\n",
      "Epoch 531/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0941 - accuracy: 0.5461 - val_loss: 1.0840 - val_accuracy: 0.5476\n",
      "Epoch 532/600\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.0984 - accuracy: 0.5438 - val_loss: 1.0840 - val_accuracy: 0.5457\n",
      "Epoch 533/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0968 - accuracy: 0.5408 - val_loss: 1.0843 - val_accuracy: 0.5404\n",
      "Epoch 534/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0982 - accuracy: 0.5391 - val_loss: 1.0837 - val_accuracy: 0.5466\n",
      "Epoch 535/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0942 - accuracy: 0.5442 - val_loss: 1.0834 - val_accuracy: 0.5496\n",
      "Epoch 536/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0959 - accuracy: 0.5434 - val_loss: 1.0837 - val_accuracy: 0.5456\n",
      "Epoch 537/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.0972 - accuracy: 0.5446 - val_loss: 1.0840 - val_accuracy: 0.5457\n",
      "Epoch 538/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0999 - accuracy: 0.5402 - val_loss: 1.0836 - val_accuracy: 0.5454\n",
      "Epoch 539/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0976 - accuracy: 0.5398 - val_loss: 1.0833 - val_accuracy: 0.5461\n",
      "Epoch 540/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0996 - accuracy: 0.5392 - val_loss: 1.0833 - val_accuracy: 0.5489\n",
      "Epoch 541/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0997 - accuracy: 0.5393 - val_loss: 1.0836 - val_accuracy: 0.5466\n",
      "Epoch 542/600\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.0933 - accuracy: 0.5432 - val_loss: 1.0834 - val_accuracy: 0.5496\n",
      "Epoch 543/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0942 - accuracy: 0.5434 - val_loss: 1.0832 - val_accuracy: 0.5461\n",
      "Epoch 544/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0921 - accuracy: 0.5382 - val_loss: 1.0835 - val_accuracy: 0.5422\n",
      "Epoch 545/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0988 - accuracy: 0.5400 - val_loss: 1.0829 - val_accuracy: 0.5485\n",
      "Epoch 546/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.0954 - accuracy: 0.5442 - val_loss: 1.0832 - val_accuracy: 0.5449\n",
      "Epoch 547/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.0960 - accuracy: 0.5413 - val_loss: 1.0836 - val_accuracy: 0.5425\n",
      "Epoch 548/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0978 - accuracy: 0.5431 - val_loss: 1.0836 - val_accuracy: 0.5504\n",
      "Epoch 549/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0983 - accuracy: 0.5432 - val_loss: 1.0836 - val_accuracy: 0.5474\n",
      "Epoch 550/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0974 - accuracy: 0.5393 - val_loss: 1.0841 - val_accuracy: 0.5425\n",
      "Epoch 551/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0969 - accuracy: 0.5406 - val_loss: 1.0832 - val_accuracy: 0.5476\n",
      "Epoch 552/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0938 - accuracy: 0.5425 - val_loss: 1.0831 - val_accuracy: 0.5479\n",
      "Epoch 553/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0976 - accuracy: 0.5407 - val_loss: 1.0828 - val_accuracy: 0.5479\n",
      "Epoch 554/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0975 - accuracy: 0.5434 - val_loss: 1.0828 - val_accuracy: 0.5465\n",
      "Epoch 555/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.0973 - accuracy: 0.5414 - val_loss: 1.0825 - val_accuracy: 0.5496\n",
      "Epoch 556/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0972 - accuracy: 0.5430 - val_loss: 1.0826 - val_accuracy: 0.5488\n",
      "Epoch 557/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0963 - accuracy: 0.5448 - val_loss: 1.0829 - val_accuracy: 0.5414\n",
      "Epoch 558/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.0967 - accuracy: 0.5418 - val_loss: 1.0830 - val_accuracy: 0.5382\n",
      "Epoch 559/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.0955 - accuracy: 0.5456 - val_loss: 1.0822 - val_accuracy: 0.5473\n",
      "Epoch 560/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0963 - accuracy: 0.5438 - val_loss: 1.0823 - val_accuracy: 0.5485\n",
      "Epoch 561/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0941 - accuracy: 0.5426 - val_loss: 1.0830 - val_accuracy: 0.5433\n",
      "Epoch 562/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0942 - accuracy: 0.5406 - val_loss: 1.0827 - val_accuracy: 0.5480\n",
      "Epoch 563/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0960 - accuracy: 0.5402 - val_loss: 1.0825 - val_accuracy: 0.5480\n",
      "Epoch 564/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0933 - accuracy: 0.5436 - val_loss: 1.0828 - val_accuracy: 0.5421\n",
      "Epoch 565/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0990 - accuracy: 0.5399 - val_loss: 1.0825 - val_accuracy: 0.5477\n",
      "Epoch 566/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0941 - accuracy: 0.5430 - val_loss: 1.0824 - val_accuracy: 0.5476\n",
      "Epoch 567/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0935 - accuracy: 0.5430 - val_loss: 1.0826 - val_accuracy: 0.5437\n",
      "Epoch 568/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0940 - accuracy: 0.5420 - val_loss: 1.0823 - val_accuracy: 0.5493\n",
      "Epoch 569/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0953 - accuracy: 0.5411 - val_loss: 1.0822 - val_accuracy: 0.5505\n",
      "Epoch 570/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0941 - accuracy: 0.5417 - val_loss: 1.0819 - val_accuracy: 0.5474\n",
      "Epoch 571/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0923 - accuracy: 0.5434 - val_loss: 1.0817 - val_accuracy: 0.5442\n",
      "Epoch 572/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0965 - accuracy: 0.5442 - val_loss: 1.0815 - val_accuracy: 0.5452\n",
      "Epoch 573/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0955 - accuracy: 0.5398 - val_loss: 1.0816 - val_accuracy: 0.5476\n",
      "Epoch 574/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0948 - accuracy: 0.5430 - val_loss: 1.0814 - val_accuracy: 0.5487\n",
      "Epoch 575/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.0935 - accuracy: 0.5408 - val_loss: 1.0816 - val_accuracy: 0.5491\n",
      "Epoch 576/600\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0941 - accuracy: 0.5414 - val_loss: 1.0819 - val_accuracy: 0.5446\n",
      "Epoch 577/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0926 - accuracy: 0.5442 - val_loss: 1.0813 - val_accuracy: 0.5481\n",
      "Epoch 578/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0942 - accuracy: 0.5427 - val_loss: 1.0815 - val_accuracy: 0.5493\n",
      "Epoch 579/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0958 - accuracy: 0.5431 - val_loss: 1.0813 - val_accuracy: 0.5473\n",
      "Epoch 580/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0946 - accuracy: 0.5440 - val_loss: 1.0811 - val_accuracy: 0.5484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0937 - accuracy: 0.5442 - val_loss: 1.0809 - val_accuracy: 0.5483\n",
      "Epoch 582/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0938 - accuracy: 0.5440 - val_loss: 1.0807 - val_accuracy: 0.5495\n",
      "Epoch 583/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0938 - accuracy: 0.5434 - val_loss: 1.0809 - val_accuracy: 0.5485\n",
      "Epoch 584/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0938 - accuracy: 0.5440 - val_loss: 1.0812 - val_accuracy: 0.5470\n",
      "Epoch 585/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.0923 - accuracy: 0.5415 - val_loss: 1.0808 - val_accuracy: 0.5473\n",
      "Epoch 586/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0916 - accuracy: 0.5450 - val_loss: 1.0808 - val_accuracy: 0.5476\n",
      "Epoch 587/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0954 - accuracy: 0.5400 - val_loss: 1.0807 - val_accuracy: 0.5488\n",
      "Epoch 588/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0954 - accuracy: 0.5440 - val_loss: 1.0809 - val_accuracy: 0.5439\n",
      "Epoch 589/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.0931 - accuracy: 0.5456 - val_loss: 1.0808 - val_accuracy: 0.5485\n",
      "Epoch 590/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0939 - accuracy: 0.5456 - val_loss: 1.0806 - val_accuracy: 0.5495\n",
      "Epoch 591/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0958 - accuracy: 0.5460 - val_loss: 1.0803 - val_accuracy: 0.5473\n",
      "Epoch 592/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0947 - accuracy: 0.5428 - val_loss: 1.0807 - val_accuracy: 0.5427\n",
      "Epoch 593/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0939 - accuracy: 0.5436 - val_loss: 1.0805 - val_accuracy: 0.5479\n",
      "Epoch 594/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0941 - accuracy: 0.5438 - val_loss: 1.0808 - val_accuracy: 0.5488\n",
      "Epoch 595/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0950 - accuracy: 0.5436 - val_loss: 1.0807 - val_accuracy: 0.5488\n",
      "Epoch 596/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0940 - accuracy: 0.5446 - val_loss: 1.0804 - val_accuracy: 0.5501\n",
      "Epoch 597/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.0947 - accuracy: 0.5452 - val_loss: 1.0803 - val_accuracy: 0.5483\n",
      "Epoch 598/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0928 - accuracy: 0.5450 - val_loss: 1.0800 - val_accuracy: 0.5477\n",
      "Epoch 599/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0922 - accuracy: 0.5432 - val_loss: 1.0798 - val_accuracy: 0.5476\n",
      "Epoch 600/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0957 - accuracy: 0.5432 - val_loss: 1.0799 - val_accuracy: 0.5468\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(len(columns[0]),)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.33)\n",
    "\n",
    "def display_training_graph(history):\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['val_loss', 'loss'], loc='upper right')\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "display_training_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0839 - accuracy: 0.5489\n",
      "Test accuracy: 0.5488628149032593\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "evaluation_score = model.evaluate(x_eval, y_eval,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', evaluation_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nkillwound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unlabelled rows:\n",
      "163325\n",
      "\n",
      "Number of unlabelled rows with valid nkillwound\n",
      "145140\n"
     ]
    }
   ],
   "source": [
    "# Total\n",
    "print('Total number of unlabelled rows:')\n",
    "print(unlabelled.shape[0])\n",
    "\n",
    "# Valid nperps\n",
    "print('\\nNumber of unlabelled rows with valid nkillwound')\n",
    "print(unlabelled[(unlabelled[\"nkillwound\"].notnull())].shape[0])\n",
    "\n",
    "# Introducing unlabelled_nperps\n",
    "unlabelled_nkillwound = unlabelled[(unlabelled[\"nkillwound\"].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145140, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>nkillwound</th>\n",
       "      <th>attacktype1</th>\n",
       "      <th>targtype1</th>\n",
       "      <th>weaptype1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197000000001</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197001000001</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197001010002</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197001020002</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197001050001</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              region  nkillwound  attacktype1  targtype1  weaptype1\n",
       "eventid                                                            \n",
       "197000000001       2           1            1         14         13\n",
       "197001000001       5           1            1         10         13\n",
       "197001010002       1           0            2          3          5\n",
       "197001020002       1           0            3         21          6\n",
       "197001050001       1           0            3          4          6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all fields to int from float \n",
    "labelled_nkillwound = labelled[cols_for_learning_nkillwound].astype('int32')\n",
    "unlabelled_nkillwound = unlabelled_nkillwound[cols_for_learning_nkillwound[:-1]].astype('int32')\n",
    "\n",
    "print(unlabelled_nkillwound.shape)\n",
    "unlabelled_nkillwound.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_split = 0.8\n",
    "# max_words = 1000\n",
    "batch_size = 10000\n",
    "epochs = 600\n",
    "\n",
    "labelled_nkillwound = labelled_nkillwound.sample(frac=1) # Shuffle labelled set\n",
    "\n",
    "columns = labelled_nkillwound[['region','attacktype1','targtype1','weaptype1']].to_numpy()\n",
    "clusters = labelled_nkillwound['cluster'].to_numpy()\n",
    "\n",
    "num_classes = np.max(clusters) - np.min(clusters) + 1\n",
    "clusters = utils.to_categorical(clusters, num_classes)\n",
    "\n",
    "train_size = int(len(labelled_nkillwound) * percentage_split) \n",
    "\n",
    "x_train = columns[:train_size]\n",
    "y_train = clusters[:train_size]\n",
    "\n",
    "x_eval = columns[train_size:]\n",
    "y_eval = clusters[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 1.7611 - accuracy: 0.2645 - val_loss: 1.3503 - val_accuracy: 0.3297\n",
      "Epoch 2/600\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.6154 - accuracy: 0.2930 - val_loss: 1.3683 - val_accuracy: 0.3496\n",
      "Epoch 3/600\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.5952 - accuracy: 0.3212 - val_loss: 1.3355 - val_accuracy: 0.3496\n",
      "Epoch 4/600\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.5509 - accuracy: 0.3364 - val_loss: 1.2773 - val_accuracy: 0.4005\n",
      "Epoch 5/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.5002 - accuracy: 0.3405 - val_loss: 1.2564 - val_accuracy: 0.4301\n",
      "Epoch 6/600\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.4792 - accuracy: 0.3440 - val_loss: 1.2598 - val_accuracy: 0.4353\n",
      "Epoch 7/600\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.4642 - accuracy: 0.3538 - val_loss: 1.2518 - val_accuracy: 0.4437\n",
      "Epoch 8/600\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.4307 - accuracy: 0.3745 - val_loss: 1.2354 - val_accuracy: 0.4501\n",
      "Epoch 9/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.4140 - accuracy: 0.3815 - val_loss: 1.2291 - val_accuracy: 0.4387\n",
      "Epoch 10/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.4000 - accuracy: 0.3881 - val_loss: 1.2306 - val_accuracy: 0.4403\n",
      "Epoch 11/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.3862 - accuracy: 0.3938 - val_loss: 1.2279 - val_accuracy: 0.4421\n",
      "Epoch 12/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.3816 - accuracy: 0.3933 - val_loss: 1.2204 - val_accuracy: 0.4433\n",
      "Epoch 13/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.3578 - accuracy: 0.3997 - val_loss: 1.2156 - val_accuracy: 0.4500\n",
      "Epoch 14/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.3473 - accuracy: 0.4084 - val_loss: 1.2143 - val_accuracy: 0.4474\n",
      "Epoch 15/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.3470 - accuracy: 0.4141 - val_loss: 1.2127 - val_accuracy: 0.4486\n",
      "Epoch 16/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.3361 - accuracy: 0.4096 - val_loss: 1.2092 - val_accuracy: 0.4496\n",
      "Epoch 17/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.3222 - accuracy: 0.4174 - val_loss: 1.2067 - val_accuracy: 0.4492\n",
      "Epoch 18/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.3164 - accuracy: 0.4214 - val_loss: 1.2055 - val_accuracy: 0.4559\n",
      "Epoch 19/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.3126 - accuracy: 0.4196 - val_loss: 1.2048 - val_accuracy: 0.4581\n",
      "Epoch 20/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.3031 - accuracy: 0.4249 - val_loss: 1.2027 - val_accuracy: 0.4550\n",
      "Epoch 21/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.3003 - accuracy: 0.4256 - val_loss: 1.2006 - val_accuracy: 0.4575\n",
      "Epoch 22/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.2889 - accuracy: 0.4315 - val_loss: 1.1992 - val_accuracy: 0.4661\n",
      "Epoch 23/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.2893 - accuracy: 0.4320 - val_loss: 1.1985 - val_accuracy: 0.4787\n",
      "Epoch 24/600\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.2777 - accuracy: 0.4373 - val_loss: 1.1976 - val_accuracy: 0.4811\n",
      "Epoch 25/600\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.2752 - accuracy: 0.4430 - val_loss: 1.1964 - val_accuracy: 0.4792\n",
      "Epoch 26/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.2721 - accuracy: 0.4402 - val_loss: 1.1951 - val_accuracy: 0.4707\n",
      "Epoch 27/600\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.2683 - accuracy: 0.4407 - val_loss: 1.1940 - val_accuracy: 0.4702\n",
      "Epoch 28/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.2597 - accuracy: 0.4476 - val_loss: 1.1928 - val_accuracy: 0.4711\n",
      "Epoch 29/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.2608 - accuracy: 0.4520 - val_loss: 1.1916 - val_accuracy: 0.4756\n",
      "Epoch 30/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.2518 - accuracy: 0.4487 - val_loss: 1.1907 - val_accuracy: 0.4845\n",
      "Epoch 31/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.2450 - accuracy: 0.4493 - val_loss: 1.1894 - val_accuracy: 0.4838\n",
      "Epoch 32/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.2474 - accuracy: 0.4547 - val_loss: 1.1878 - val_accuracy: 0.4849\n",
      "Epoch 33/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.2465 - accuracy: 0.4546 - val_loss: 1.1864 - val_accuracy: 0.4999\n",
      "Epoch 34/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.2396 - accuracy: 0.4558 - val_loss: 1.1854 - val_accuracy: 0.5042\n",
      "Epoch 35/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.2373 - accuracy: 0.4598 - val_loss: 1.1844 - val_accuracy: 0.5063\n",
      "Epoch 36/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.2345 - accuracy: 0.4560 - val_loss: 1.1827 - val_accuracy: 0.5068\n",
      "Epoch 37/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.2305 - accuracy: 0.4665 - val_loss: 1.1809 - val_accuracy: 0.5071\n",
      "Epoch 38/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.2290 - accuracy: 0.4657 - val_loss: 1.1793 - val_accuracy: 0.5084\n",
      "Epoch 39/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.2271 - accuracy: 0.4620 - val_loss: 1.1778 - val_accuracy: 0.5087\n",
      "Epoch 40/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.2209 - accuracy: 0.4666 - val_loss: 1.1763 - val_accuracy: 0.5085\n",
      "Epoch 41/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.2183 - accuracy: 0.4680 - val_loss: 1.1753 - val_accuracy: 0.5072\n",
      "Epoch 42/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.2126 - accuracy: 0.4771 - val_loss: 1.1743 - val_accuracy: 0.5065\n",
      "Epoch 43/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.2136 - accuracy: 0.4763 - val_loss: 1.1730 - val_accuracy: 0.5067\n",
      "Epoch 44/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.2130 - accuracy: 0.4749 - val_loss: 1.1715 - val_accuracy: 0.5080\n",
      "Epoch 45/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.2083 - accuracy: 0.4745 - val_loss: 1.1700 - val_accuracy: 0.5084\n",
      "Epoch 46/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.2078 - accuracy: 0.4765 - val_loss: 1.1687 - val_accuracy: 0.5076\n",
      "Epoch 47/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.2052 - accuracy: 0.4798 - val_loss: 1.1678 - val_accuracy: 0.5085\n",
      "Epoch 48/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.2030 - accuracy: 0.4757 - val_loss: 1.1668 - val_accuracy: 0.5092\n",
      "Epoch 49/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.2025 - accuracy: 0.4808 - val_loss: 1.1659 - val_accuracy: 0.5102\n",
      "Epoch 50/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1984 - accuracy: 0.4830 - val_loss: 1.1648 - val_accuracy: 0.5096\n",
      "Epoch 51/600\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.1998 - accuracy: 0.4868 - val_loss: 1.1631 - val_accuracy: 0.5100\n",
      "Epoch 52/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1930 - accuracy: 0.4861 - val_loss: 1.1616 - val_accuracy: 0.5100\n",
      "Epoch 53/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1922 - accuracy: 0.4897 - val_loss: 1.1603 - val_accuracy: 0.5102\n",
      "Epoch 54/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1931 - accuracy: 0.4891 - val_loss: 1.1594 - val_accuracy: 0.5129\n",
      "Epoch 55/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1884 - accuracy: 0.4891 - val_loss: 1.1588 - val_accuracy: 0.5108\n",
      "Epoch 56/600\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.1884 - accuracy: 0.4906 - val_loss: 1.1581 - val_accuracy: 0.5092\n",
      "Epoch 57/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1852 - accuracy: 0.4947 - val_loss: 1.1570 - val_accuracy: 0.5092\n",
      "Epoch 58/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1885 - accuracy: 0.4917 - val_loss: 1.1556 - val_accuracy: 0.5129\n",
      "Epoch 59/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1813 - accuracy: 0.4948 - val_loss: 1.1546 - val_accuracy: 0.5126\n",
      "Epoch 60/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1829 - accuracy: 0.4952 - val_loss: 1.1535 - val_accuracy: 0.5114\n",
      "Epoch 61/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1804 - accuracy: 0.4983 - val_loss: 1.1524 - val_accuracy: 0.5112\n",
      "Epoch 62/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1820 - accuracy: 0.4966 - val_loss: 1.1513 - val_accuracy: 0.5112\n",
      "Epoch 63/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1793 - accuracy: 0.4952 - val_loss: 1.1502 - val_accuracy: 0.5114\n",
      "Epoch 64/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1745 - accuracy: 0.4985 - val_loss: 1.1495 - val_accuracy: 0.5104\n",
      "Epoch 65/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1743 - accuracy: 0.5009 - val_loss: 1.1488 - val_accuracy: 0.5088\n",
      "Epoch 66/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1741 - accuracy: 0.5009 - val_loss: 1.1479 - val_accuracy: 0.5103\n",
      "Epoch 67/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1734 - accuracy: 0.4996 - val_loss: 1.1470 - val_accuracy: 0.5106\n",
      "Epoch 68/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1721 - accuracy: 0.5030 - val_loss: 1.1462 - val_accuracy: 0.5094\n",
      "Epoch 69/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1730 - accuracy: 0.5001 - val_loss: 1.1455 - val_accuracy: 0.5110\n",
      "Epoch 70/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1691 - accuracy: 0.4994 - val_loss: 1.1448 - val_accuracy: 0.5085\n",
      "Epoch 71/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1724 - accuracy: 0.5030 - val_loss: 1.1439 - val_accuracy: 0.5087\n",
      "Epoch 72/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1681 - accuracy: 0.5042 - val_loss: 1.1429 - val_accuracy: 0.5090\n",
      "Epoch 73/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1671 - accuracy: 0.5034 - val_loss: 1.1422 - val_accuracy: 0.5095\n",
      "Epoch 74/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1677 - accuracy: 0.5059 - val_loss: 1.1418 - val_accuracy: 0.5102\n",
      "Epoch 75/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1641 - accuracy: 0.5056 - val_loss: 1.1410 - val_accuracy: 0.5114\n",
      "Epoch 76/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1609 - accuracy: 0.5018 - val_loss: 1.1404 - val_accuracy: 0.5112\n",
      "Epoch 77/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1671 - accuracy: 0.5031 - val_loss: 1.1396 - val_accuracy: 0.5114\n",
      "Epoch 78/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1639 - accuracy: 0.5037 - val_loss: 1.1392 - val_accuracy: 0.5080\n",
      "Epoch 79/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1661 - accuracy: 0.5040 - val_loss: 1.1387 - val_accuracy: 0.5079\n",
      "Epoch 80/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1605 - accuracy: 0.5069 - val_loss: 1.1382 - val_accuracy: 0.5100\n",
      "Epoch 81/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1640 - accuracy: 0.5015 - val_loss: 1.1375 - val_accuracy: 0.5098\n",
      "Epoch 82/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1627 - accuracy: 0.5072 - val_loss: 1.1367 - val_accuracy: 0.5103\n",
      "Epoch 83/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1622 - accuracy: 0.5077 - val_loss: 1.1365 - val_accuracy: 0.5092\n",
      "Epoch 84/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1611 - accuracy: 0.5036 - val_loss: 1.1363 - val_accuracy: 0.5096\n",
      "Epoch 85/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1597 - accuracy: 0.5089 - val_loss: 1.1357 - val_accuracy: 0.5110\n",
      "Epoch 86/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1580 - accuracy: 0.5056 - val_loss: 1.1352 - val_accuracy: 0.5120\n",
      "Epoch 87/600\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 1.1576 - accuracy: 0.5079 - val_loss: 1.1345 - val_accuracy: 0.5122\n",
      "Epoch 88/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1563 - accuracy: 0.5076 - val_loss: 1.1340 - val_accuracy: 0.5161\n",
      "Epoch 89/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1528 - accuracy: 0.5125 - val_loss: 1.1334 - val_accuracy: 0.5149\n",
      "Epoch 90/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1544 - accuracy: 0.5105 - val_loss: 1.1329 - val_accuracy: 0.5154\n",
      "Epoch 91/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1566 - accuracy: 0.5080 - val_loss: 1.1324 - val_accuracy: 0.5166\n",
      "Epoch 92/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1564 - accuracy: 0.5077 - val_loss: 1.1321 - val_accuracy: 0.5181\n",
      "Epoch 93/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1516 - accuracy: 0.5121 - val_loss: 1.1316 - val_accuracy: 0.5180\n",
      "Epoch 94/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1526 - accuracy: 0.5125 - val_loss: 1.1312 - val_accuracy: 0.5174\n",
      "Epoch 95/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1531 - accuracy: 0.5087 - val_loss: 1.1308 - val_accuracy: 0.5155\n",
      "Epoch 96/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1508 - accuracy: 0.5100 - val_loss: 1.1301 - val_accuracy: 0.5170\n",
      "Epoch 97/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1507 - accuracy: 0.5099 - val_loss: 1.1298 - val_accuracy: 0.5170\n",
      "Epoch 98/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1502 - accuracy: 0.5105 - val_loss: 1.1296 - val_accuracy: 0.5145\n",
      "Epoch 99/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1521 - accuracy: 0.5138 - val_loss: 1.1293 - val_accuracy: 0.5141\n",
      "Epoch 100/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1547 - accuracy: 0.5082 - val_loss: 1.1287 - val_accuracy: 0.5131\n",
      "Epoch 101/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1480 - accuracy: 0.5115 - val_loss: 1.1284 - val_accuracy: 0.5155\n",
      "Epoch 102/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1528 - accuracy: 0.5088 - val_loss: 1.1280 - val_accuracy: 0.5157\n",
      "Epoch 103/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1481 - accuracy: 0.5086 - val_loss: 1.1278 - val_accuracy: 0.5184\n",
      "Epoch 104/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1501 - accuracy: 0.5101 - val_loss: 1.1275 - val_accuracy: 0.5177\n",
      "Epoch 105/600\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.1513 - accuracy: 0.5138 - val_loss: 1.1270 - val_accuracy: 0.5170\n",
      "Epoch 106/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1462 - accuracy: 0.5103 - val_loss: 1.1264 - val_accuracy: 0.5172\n",
      "Epoch 107/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1463 - accuracy: 0.5149 - val_loss: 1.1260 - val_accuracy: 0.5169\n",
      "Epoch 108/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1473 - accuracy: 0.5090 - val_loss: 1.1255 - val_accuracy: 0.5176\n",
      "Epoch 109/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1482 - accuracy: 0.5109 - val_loss: 1.1251 - val_accuracy: 0.5182\n",
      "Epoch 110/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1439 - accuracy: 0.5119 - val_loss: 1.1248 - val_accuracy: 0.5203\n",
      "Epoch 111/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1452 - accuracy: 0.5141 - val_loss: 1.1243 - val_accuracy: 0.5200\n",
      "Epoch 112/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1469 - accuracy: 0.5149 - val_loss: 1.1238 - val_accuracy: 0.5193\n",
      "Epoch 113/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1468 - accuracy: 0.5115 - val_loss: 1.1237 - val_accuracy: 0.5170\n",
      "Epoch 114/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1453 - accuracy: 0.5118 - val_loss: 1.1235 - val_accuracy: 0.5172\n",
      "Epoch 115/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1435 - accuracy: 0.5163 - val_loss: 1.1231 - val_accuracy: 0.5165\n",
      "Epoch 116/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1476 - accuracy: 0.5107 - val_loss: 1.1231 - val_accuracy: 0.5168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1410 - accuracy: 0.5178 - val_loss: 1.1226 - val_accuracy: 0.5170\n",
      "Epoch 118/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1426 - accuracy: 0.5137 - val_loss: 1.1220 - val_accuracy: 0.5186\n",
      "Epoch 119/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1421 - accuracy: 0.5156 - val_loss: 1.1219 - val_accuracy: 0.5186\n",
      "Epoch 120/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1426 - accuracy: 0.5160 - val_loss: 1.1222 - val_accuracy: 0.5192\n",
      "Epoch 121/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1441 - accuracy: 0.5143 - val_loss: 1.1220 - val_accuracy: 0.5161\n",
      "Epoch 122/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1434 - accuracy: 0.5167 - val_loss: 1.1215 - val_accuracy: 0.5172\n",
      "Epoch 123/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1401 - accuracy: 0.5180 - val_loss: 1.1209 - val_accuracy: 0.5173\n",
      "Epoch 124/600\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1395 - accuracy: 0.5123 - val_loss: 1.1205 - val_accuracy: 0.5178\n",
      "Epoch 125/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1419 - accuracy: 0.5170 - val_loss: 1.1200 - val_accuracy: 0.5184\n",
      "Epoch 126/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1416 - accuracy: 0.5164 - val_loss: 1.1197 - val_accuracy: 0.5162\n",
      "Epoch 127/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1382 - accuracy: 0.5223 - val_loss: 1.1196 - val_accuracy: 0.5168\n",
      "Epoch 128/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1397 - accuracy: 0.5136 - val_loss: 1.1197 - val_accuracy: 0.5177\n",
      "Epoch 129/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1369 - accuracy: 0.5203 - val_loss: 1.1191 - val_accuracy: 0.5169\n",
      "Epoch 130/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1395 - accuracy: 0.5161 - val_loss: 1.1186 - val_accuracy: 0.5169\n",
      "Epoch 131/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1401 - accuracy: 0.5172 - val_loss: 1.1184 - val_accuracy: 0.5205\n",
      "Epoch 132/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1393 - accuracy: 0.5139 - val_loss: 1.1181 - val_accuracy: 0.5208\n",
      "Epoch 133/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1384 - accuracy: 0.5178 - val_loss: 1.1178 - val_accuracy: 0.5251\n",
      "Epoch 134/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1374 - accuracy: 0.5203 - val_loss: 1.1174 - val_accuracy: 0.5201\n",
      "Epoch 135/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1361 - accuracy: 0.5149 - val_loss: 1.1173 - val_accuracy: 0.5248\n",
      "Epoch 136/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1375 - accuracy: 0.5172 - val_loss: 1.1170 - val_accuracy: 0.5203\n",
      "Epoch 137/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1354 - accuracy: 0.5184 - val_loss: 1.1166 - val_accuracy: 0.5178\n",
      "Epoch 138/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1376 - accuracy: 0.5170 - val_loss: 1.1160 - val_accuracy: 0.5164\n",
      "Epoch 139/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1357 - accuracy: 0.5223 - val_loss: 1.1159 - val_accuracy: 0.5247\n",
      "Epoch 140/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1324 - accuracy: 0.5219 - val_loss: 1.1160 - val_accuracy: 0.5258\n",
      "Epoch 141/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1355 - accuracy: 0.5172 - val_loss: 1.1156 - val_accuracy: 0.5282\n",
      "Epoch 142/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1373 - accuracy: 0.5180 - val_loss: 1.1151 - val_accuracy: 0.5259\n",
      "Epoch 143/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1320 - accuracy: 0.5182 - val_loss: 1.1149 - val_accuracy: 0.5258\n",
      "Epoch 144/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1325 - accuracy: 0.5190 - val_loss: 1.1147 - val_accuracy: 0.5244\n",
      "Epoch 145/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1330 - accuracy: 0.5202 - val_loss: 1.1146 - val_accuracy: 0.5228\n",
      "Epoch 146/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1341 - accuracy: 0.5222 - val_loss: 1.1147 - val_accuracy: 0.5239\n",
      "Epoch 147/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1337 - accuracy: 0.5226 - val_loss: 1.1141 - val_accuracy: 0.5238\n",
      "Epoch 148/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1325 - accuracy: 0.5233 - val_loss: 1.1138 - val_accuracy: 0.5252\n",
      "Epoch 149/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1337 - accuracy: 0.5244 - val_loss: 1.1138 - val_accuracy: 0.5235\n",
      "Epoch 150/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1347 - accuracy: 0.5206 - val_loss: 1.1137 - val_accuracy: 0.5244\n",
      "Epoch 151/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1318 - accuracy: 0.5184 - val_loss: 1.1134 - val_accuracy: 0.5239\n",
      "Epoch 152/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1335 - accuracy: 0.5188 - val_loss: 1.1130 - val_accuracy: 0.5227\n",
      "Epoch 153/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1315 - accuracy: 0.5196 - val_loss: 1.1126 - val_accuracy: 0.5232\n",
      "Epoch 154/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1338 - accuracy: 0.5197 - val_loss: 1.1124 - val_accuracy: 0.5240\n",
      "Epoch 155/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1329 - accuracy: 0.5227 - val_loss: 1.1121 - val_accuracy: 0.5240\n",
      "Epoch 156/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1286 - accuracy: 0.5200 - val_loss: 1.1120 - val_accuracy: 0.5203\n",
      "Epoch 157/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1292 - accuracy: 0.5228 - val_loss: 1.1115 - val_accuracy: 0.5211\n",
      "Epoch 158/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1313 - accuracy: 0.5192 - val_loss: 1.1111 - val_accuracy: 0.5223\n",
      "Epoch 159/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1306 - accuracy: 0.5202 - val_loss: 1.1107 - val_accuracy: 0.5240\n",
      "Epoch 160/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1279 - accuracy: 0.5196 - val_loss: 1.1104 - val_accuracy: 0.5250\n",
      "Epoch 161/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1322 - accuracy: 0.5232 - val_loss: 1.1104 - val_accuracy: 0.5248\n",
      "Epoch 162/600\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.1291 - accuracy: 0.5217 - val_loss: 1.1104 - val_accuracy: 0.5232\n",
      "Epoch 163/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1287 - accuracy: 0.5223 - val_loss: 1.1104 - val_accuracy: 0.5252\n",
      "Epoch 164/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1288 - accuracy: 0.5211 - val_loss: 1.1101 - val_accuracy: 0.5230\n",
      "Epoch 165/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1285 - accuracy: 0.5240 - val_loss: 1.1101 - val_accuracy: 0.5246\n",
      "Epoch 166/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1283 - accuracy: 0.5228 - val_loss: 1.1098 - val_accuracy: 0.5246\n",
      "Epoch 167/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1284 - accuracy: 0.5222 - val_loss: 1.1093 - val_accuracy: 0.5227\n",
      "Epoch 168/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1291 - accuracy: 0.5237 - val_loss: 1.1091 - val_accuracy: 0.5236\n",
      "Epoch 169/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1299 - accuracy: 0.5184 - val_loss: 1.1091 - val_accuracy: 0.5242\n",
      "Epoch 170/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1300 - accuracy: 0.5206 - val_loss: 1.1090 - val_accuracy: 0.5223\n",
      "Epoch 171/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1281 - accuracy: 0.5214 - val_loss: 1.1089 - val_accuracy: 0.5227\n",
      "Epoch 172/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1281 - accuracy: 0.5240 - val_loss: 1.1090 - val_accuracy: 0.5244\n",
      "Epoch 173/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1299 - accuracy: 0.5207 - val_loss: 1.1083 - val_accuracy: 0.5247\n",
      "Epoch 174/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1271 - accuracy: 0.5214 - val_loss: 1.1077 - val_accuracy: 0.5239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1247 - accuracy: 0.5224 - val_loss: 1.1074 - val_accuracy: 0.5256\n",
      "Epoch 176/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1283 - accuracy: 0.5232 - val_loss: 1.1076 - val_accuracy: 0.5250\n",
      "Epoch 177/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1295 - accuracy: 0.5243 - val_loss: 1.1073 - val_accuracy: 0.5265\n",
      "Epoch 178/600\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.1278 - accuracy: 0.5239 - val_loss: 1.1069 - val_accuracy: 0.5256\n",
      "Epoch 179/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1222 - accuracy: 0.5233 - val_loss: 1.1070 - val_accuracy: 0.5243\n",
      "Epoch 180/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1247 - accuracy: 0.5273 - val_loss: 1.1073 - val_accuracy: 0.5238\n",
      "Epoch 181/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1272 - accuracy: 0.5255 - val_loss: 1.1067 - val_accuracy: 0.5236\n",
      "Epoch 182/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1218 - accuracy: 0.5253 - val_loss: 1.1064 - val_accuracy: 0.5232\n",
      "Epoch 183/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1274 - accuracy: 0.5248 - val_loss: 1.1065 - val_accuracy: 0.5232\n",
      "Epoch 184/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1253 - accuracy: 0.5263 - val_loss: 1.1064 - val_accuracy: 0.5289\n",
      "Epoch 185/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1252 - accuracy: 0.5232 - val_loss: 1.1060 - val_accuracy: 0.5251\n",
      "Epoch 186/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1275 - accuracy: 0.5244 - val_loss: 1.1056 - val_accuracy: 0.5230\n",
      "Epoch 187/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1241 - accuracy: 0.5237 - val_loss: 1.1054 - val_accuracy: 0.5256\n",
      "Epoch 188/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1273 - accuracy: 0.5245 - val_loss: 1.1060 - val_accuracy: 0.5304\n",
      "Epoch 189/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1250 - accuracy: 0.5247 - val_loss: 1.1056 - val_accuracy: 0.5277\n",
      "Epoch 190/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1252 - accuracy: 0.5279 - val_loss: 1.1051 - val_accuracy: 0.5232\n",
      "Epoch 191/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1241 - accuracy: 0.5256 - val_loss: 1.1050 - val_accuracy: 0.5247\n",
      "Epoch 192/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1228 - accuracy: 0.5255 - val_loss: 1.1052 - val_accuracy: 0.5302\n",
      "Epoch 193/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1246 - accuracy: 0.5243 - val_loss: 1.1047 - val_accuracy: 0.5291\n",
      "Epoch 194/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1254 - accuracy: 0.5250 - val_loss: 1.1041 - val_accuracy: 0.5239\n",
      "Epoch 195/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1247 - accuracy: 0.5265 - val_loss: 1.1040 - val_accuracy: 0.5285\n",
      "Epoch 196/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1247 - accuracy: 0.5238 - val_loss: 1.1044 - val_accuracy: 0.5308\n",
      "Epoch 197/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1226 - accuracy: 0.5258 - val_loss: 1.1038 - val_accuracy: 0.5277\n",
      "Epoch 198/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1215 - accuracy: 0.5303 - val_loss: 1.1036 - val_accuracy: 0.5232\n",
      "Epoch 199/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1199 - accuracy: 0.5265 - val_loss: 1.1034 - val_accuracy: 0.5247\n",
      "Epoch 200/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1216 - accuracy: 0.5258 - val_loss: 1.1034 - val_accuracy: 0.5301\n",
      "Epoch 201/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1235 - accuracy: 0.5274 - val_loss: 1.1028 - val_accuracy: 0.5281\n",
      "Epoch 202/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1256 - accuracy: 0.5235 - val_loss: 1.1027 - val_accuracy: 0.5286\n",
      "Epoch 203/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1224 - accuracy: 0.5263 - val_loss: 1.1027 - val_accuracy: 0.5254\n",
      "Epoch 204/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1190 - accuracy: 0.5271 - val_loss: 1.1022 - val_accuracy: 0.5290\n",
      "Epoch 205/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1199 - accuracy: 0.5287 - val_loss: 1.1019 - val_accuracy: 0.5252\n",
      "Epoch 206/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1224 - accuracy: 0.5267 - val_loss: 1.1018 - val_accuracy: 0.5295\n",
      "Epoch 207/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1235 - accuracy: 0.5275 - val_loss: 1.1019 - val_accuracy: 0.5294\n",
      "Epoch 208/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1208 - accuracy: 0.5274 - val_loss: 1.1016 - val_accuracy: 0.5260\n",
      "Epoch 209/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1204 - accuracy: 0.5288 - val_loss: 1.1014 - val_accuracy: 0.5285\n",
      "Epoch 210/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1195 - accuracy: 0.5260 - val_loss: 1.1013 - val_accuracy: 0.5285\n",
      "Epoch 211/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1201 - accuracy: 0.5286 - val_loss: 1.1012 - val_accuracy: 0.5282\n",
      "Epoch 212/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1188 - accuracy: 0.5267 - val_loss: 1.1009 - val_accuracy: 0.5266\n",
      "Epoch 213/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1202 - accuracy: 0.5302 - val_loss: 1.1003 - val_accuracy: 0.5282\n",
      "Epoch 214/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1184 - accuracy: 0.5259 - val_loss: 1.1005 - val_accuracy: 0.5372\n",
      "Epoch 215/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1171 - accuracy: 0.5343 - val_loss: 1.1005 - val_accuracy: 0.5378\n",
      "Epoch 216/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1184 - accuracy: 0.5309 - val_loss: 1.1002 - val_accuracy: 0.5402\n",
      "Epoch 217/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1179 - accuracy: 0.5288 - val_loss: 1.1001 - val_accuracy: 0.5316\n",
      "Epoch 218/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1194 - accuracy: 0.5281 - val_loss: 1.1002 - val_accuracy: 0.5279\n",
      "Epoch 219/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1197 - accuracy: 0.5273 - val_loss: 1.0998 - val_accuracy: 0.5286\n",
      "Epoch 220/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1195 - accuracy: 0.5263 - val_loss: 1.0996 - val_accuracy: 0.5281\n",
      "Epoch 221/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1215 - accuracy: 0.5250 - val_loss: 1.0995 - val_accuracy: 0.5255\n",
      "Epoch 222/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1188 - accuracy: 0.5296 - val_loss: 1.0995 - val_accuracy: 0.5336\n",
      "Epoch 223/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1194 - accuracy: 0.5278 - val_loss: 1.0993 - val_accuracy: 0.5339\n",
      "Epoch 224/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1185 - accuracy: 0.5302 - val_loss: 1.0995 - val_accuracy: 0.5387\n",
      "Epoch 225/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1173 - accuracy: 0.5296 - val_loss: 1.0990 - val_accuracy: 0.5306\n",
      "Epoch 226/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1207 - accuracy: 0.5257 - val_loss: 1.0990 - val_accuracy: 0.5297\n",
      "Epoch 227/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1196 - accuracy: 0.5266 - val_loss: 1.0992 - val_accuracy: 0.5403\n",
      "Epoch 228/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1200 - accuracy: 0.5262 - val_loss: 1.0992 - val_accuracy: 0.5395\n",
      "Epoch 229/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1188 - accuracy: 0.5307 - val_loss: 1.0989 - val_accuracy: 0.5367\n",
      "Epoch 230/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1191 - accuracy: 0.5297 - val_loss: 1.0984 - val_accuracy: 0.5266\n",
      "Epoch 231/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1179 - accuracy: 0.5281 - val_loss: 1.0982 - val_accuracy: 0.5251\n",
      "Epoch 232/600\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1174 - accuracy: 0.5298 - val_loss: 1.0983 - val_accuracy: 0.5399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/600\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.1153 - accuracy: 0.5293 - val_loss: 1.0980 - val_accuracy: 0.5400\n",
      "Epoch 234/600\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.1158 - accuracy: 0.5286 - val_loss: 1.0976 - val_accuracy: 0.5375\n",
      "Epoch 235/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1158 - accuracy: 0.5327 - val_loss: 1.0973 - val_accuracy: 0.5294\n",
      "Epoch 236/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1197 - accuracy: 0.5294 - val_loss: 1.0974 - val_accuracy: 0.5306\n",
      "Epoch 237/600\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.1153 - accuracy: 0.5302 - val_loss: 1.0972 - val_accuracy: 0.5308\n",
      "Epoch 238/600\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1156 - accuracy: 0.5288 - val_loss: 1.0969 - val_accuracy: 0.5395\n",
      "Epoch 239/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.1181 - accuracy: 0.5307 - val_loss: 1.0967 - val_accuracy: 0.5402\n",
      "Epoch 240/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1148 - accuracy: 0.5335 - val_loss: 1.0963 - val_accuracy: 0.5255\n",
      "Epoch 241/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1141 - accuracy: 0.5274 - val_loss: 1.0963 - val_accuracy: 0.5246\n",
      "Epoch 242/600\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.1163 - accuracy: 0.5316 - val_loss: 1.0966 - val_accuracy: 0.5399\n",
      "Epoch 243/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1164 - accuracy: 0.5320 - val_loss: 1.0966 - val_accuracy: 0.5388\n",
      "Epoch 244/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1154 - accuracy: 0.5312 - val_loss: 1.0964 - val_accuracy: 0.5263\n",
      "Epoch 245/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1127 - accuracy: 0.5286 - val_loss: 1.0964 - val_accuracy: 0.5386\n",
      "Epoch 246/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1150 - accuracy: 0.5292 - val_loss: 1.0966 - val_accuracy: 0.5402\n",
      "Epoch 247/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1140 - accuracy: 0.5339 - val_loss: 1.0958 - val_accuracy: 0.5392\n",
      "Epoch 248/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1155 - accuracy: 0.5267 - val_loss: 1.0954 - val_accuracy: 0.5399\n",
      "Epoch 249/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1141 - accuracy: 0.5323 - val_loss: 1.0956 - val_accuracy: 0.5423\n",
      "Epoch 250/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1168 - accuracy: 0.5340 - val_loss: 1.0953 - val_accuracy: 0.5441\n",
      "Epoch 251/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1138 - accuracy: 0.5300 - val_loss: 1.0951 - val_accuracy: 0.5410\n",
      "Epoch 252/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1153 - accuracy: 0.5296 - val_loss: 1.0952 - val_accuracy: 0.5407\n",
      "Epoch 253/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1162 - accuracy: 0.5318 - val_loss: 1.0953 - val_accuracy: 0.5398\n",
      "Epoch 254/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1122 - accuracy: 0.5351 - val_loss: 1.0954 - val_accuracy: 0.5400\n",
      "Epoch 255/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1156 - accuracy: 0.5280 - val_loss: 1.0949 - val_accuracy: 0.5304\n",
      "Epoch 256/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1143 - accuracy: 0.5351 - val_loss: 1.0946 - val_accuracy: 0.5265\n",
      "Epoch 257/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1130 - accuracy: 0.5304 - val_loss: 1.0949 - val_accuracy: 0.5413\n",
      "Epoch 258/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1143 - accuracy: 0.5269 - val_loss: 1.0946 - val_accuracy: 0.5398\n",
      "Epoch 259/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1120 - accuracy: 0.5322 - val_loss: 1.0945 - val_accuracy: 0.5395\n",
      "Epoch 260/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1133 - accuracy: 0.5310 - val_loss: 1.0946 - val_accuracy: 0.5407\n",
      "Epoch 261/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1153 - accuracy: 0.5298 - val_loss: 1.0941 - val_accuracy: 0.5418\n",
      "Epoch 262/600\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.1129 - accuracy: 0.5351 - val_loss: 1.0938 - val_accuracy: 0.5394\n",
      "Epoch 263/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1097 - accuracy: 0.5336 - val_loss: 1.0939 - val_accuracy: 0.5399\n",
      "Epoch 264/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1149 - accuracy: 0.5319 - val_loss: 1.0940 - val_accuracy: 0.5293\n",
      "Epoch 265/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1141 - accuracy: 0.5312 - val_loss: 1.0940 - val_accuracy: 0.5413\n",
      "Epoch 266/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1153 - accuracy: 0.5301 - val_loss: 1.0938 - val_accuracy: 0.5400\n",
      "Epoch 267/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1148 - accuracy: 0.5337 - val_loss: 1.0934 - val_accuracy: 0.5391\n",
      "Epoch 268/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1123 - accuracy: 0.5339 - val_loss: 1.0933 - val_accuracy: 0.5421\n",
      "Epoch 269/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1127 - accuracy: 0.5328 - val_loss: 1.0932 - val_accuracy: 0.5437\n",
      "Epoch 270/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1124 - accuracy: 0.5314 - val_loss: 1.0928 - val_accuracy: 0.5312\n",
      "Epoch 271/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1121 - accuracy: 0.5320 - val_loss: 1.0927 - val_accuracy: 0.5335\n",
      "Epoch 272/600\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.1159 - accuracy: 0.5310 - val_loss: 1.0926 - val_accuracy: 0.5414\n",
      "Epoch 273/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1130 - accuracy: 0.5332 - val_loss: 1.0924 - val_accuracy: 0.5400\n",
      "Epoch 274/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1099 - accuracy: 0.5357 - val_loss: 1.0922 - val_accuracy: 0.5388\n",
      "Epoch 275/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1121 - accuracy: 0.5300 - val_loss: 1.0925 - val_accuracy: 0.5399\n",
      "Epoch 276/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1123 - accuracy: 0.5300 - val_loss: 1.0928 - val_accuracy: 0.5418\n",
      "Epoch 277/600\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.1099 - accuracy: 0.5359 - val_loss: 1.0925 - val_accuracy: 0.5417\n",
      "Epoch 278/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1116 - accuracy: 0.5349 - val_loss: 1.0923 - val_accuracy: 0.5390\n",
      "Epoch 279/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1130 - accuracy: 0.5330 - val_loss: 1.0923 - val_accuracy: 0.5437\n",
      "Epoch 280/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1083 - accuracy: 0.5349 - val_loss: 1.0923 - val_accuracy: 0.5438\n",
      "Epoch 281/600\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1096 - accuracy: 0.5376 - val_loss: 1.0916 - val_accuracy: 0.5398\n",
      "Epoch 282/600\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.1121 - accuracy: 0.5306 - val_loss: 1.0914 - val_accuracy: 0.5348\n",
      "Epoch 283/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1125 - accuracy: 0.5300 - val_loss: 1.0914 - val_accuracy: 0.5398\n",
      "Epoch 284/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1105 - accuracy: 0.5358 - val_loss: 1.0917 - val_accuracy: 0.5404\n",
      "Epoch 285/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1138 - accuracy: 0.5343 - val_loss: 1.0918 - val_accuracy: 0.5395\n",
      "Epoch 286/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1122 - accuracy: 0.5318 - val_loss: 1.0918 - val_accuracy: 0.5410\n",
      "Epoch 287/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1117 - accuracy: 0.5297 - val_loss: 1.0918 - val_accuracy: 0.5415\n",
      "Epoch 288/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1086 - accuracy: 0.5363 - val_loss: 1.0914 - val_accuracy: 0.5400\n",
      "Epoch 289/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1088 - accuracy: 0.5349 - val_loss: 1.0913 - val_accuracy: 0.5392\n",
      "Epoch 290/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1140 - accuracy: 0.5333 - val_loss: 1.0915 - val_accuracy: 0.5403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1125 - accuracy: 0.5344 - val_loss: 1.0912 - val_accuracy: 0.5400\n",
      "Epoch 292/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1095 - accuracy: 0.5322 - val_loss: 1.0914 - val_accuracy: 0.5422\n",
      "Epoch 293/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1079 - accuracy: 0.5360 - val_loss: 1.0913 - val_accuracy: 0.5422\n",
      "Epoch 294/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1104 - accuracy: 0.5312 - val_loss: 1.0909 - val_accuracy: 0.5410\n",
      "Epoch 295/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1076 - accuracy: 0.5389 - val_loss: 1.0910 - val_accuracy: 0.5422\n",
      "Epoch 296/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1085 - accuracy: 0.5334 - val_loss: 1.0909 - val_accuracy: 0.5417\n",
      "Epoch 297/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1119 - accuracy: 0.5324 - val_loss: 1.0904 - val_accuracy: 0.5289\n",
      "Epoch 298/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1088 - accuracy: 0.5324 - val_loss: 1.0903 - val_accuracy: 0.5386\n",
      "Epoch 299/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1107 - accuracy: 0.5324 - val_loss: 1.0912 - val_accuracy: 0.5442\n",
      "Epoch 300/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1096 - accuracy: 0.5365 - val_loss: 1.0906 - val_accuracy: 0.5427\n",
      "Epoch 301/600\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.1065 - accuracy: 0.5382 - val_loss: 1.0906 - val_accuracy: 0.5427\n",
      "Epoch 302/600\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.1090 - accuracy: 0.5338 - val_loss: 1.0907 - val_accuracy: 0.5450\n",
      "Epoch 303/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1075 - accuracy: 0.5332 - val_loss: 1.0900 - val_accuracy: 0.5418\n",
      "Epoch 304/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1083 - accuracy: 0.5367 - val_loss: 1.0898 - val_accuracy: 0.5396\n",
      "Epoch 305/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1106 - accuracy: 0.5359 - val_loss: 1.0898 - val_accuracy: 0.5407\n",
      "Epoch 306/600\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.1087 - accuracy: 0.5362 - val_loss: 1.0898 - val_accuracy: 0.5426\n",
      "Epoch 307/600\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.1100 - accuracy: 0.5317 - val_loss: 1.0899 - val_accuracy: 0.5425\n",
      "Epoch 308/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1105 - accuracy: 0.5342 - val_loss: 1.0899 - val_accuracy: 0.5421\n",
      "Epoch 309/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1054 - accuracy: 0.5337 - val_loss: 1.0899 - val_accuracy: 0.5423\n",
      "Epoch 310/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1064 - accuracy: 0.5357 - val_loss: 1.0897 - val_accuracy: 0.5407\n",
      "Epoch 311/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1080 - accuracy: 0.5382 - val_loss: 1.0897 - val_accuracy: 0.5410\n",
      "Epoch 312/600\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.1110 - accuracy: 0.5379 - val_loss: 1.0895 - val_accuracy: 0.5430\n",
      "Epoch 313/600\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.1078 - accuracy: 0.5367 - val_loss: 1.0888 - val_accuracy: 0.5415\n",
      "Epoch 314/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1070 - accuracy: 0.5348 - val_loss: 1.0887 - val_accuracy: 0.5406\n",
      "Epoch 315/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1086 - accuracy: 0.5363 - val_loss: 1.0891 - val_accuracy: 0.5407\n",
      "Epoch 316/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1057 - accuracy: 0.5373 - val_loss: 1.0890 - val_accuracy: 0.5391\n",
      "Epoch 317/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1087 - accuracy: 0.5347 - val_loss: 1.0885 - val_accuracy: 0.5383\n",
      "Epoch 318/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1098 - accuracy: 0.5314 - val_loss: 1.0885 - val_accuracy: 0.5395\n",
      "Epoch 319/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1074 - accuracy: 0.5343 - val_loss: 1.0893 - val_accuracy: 0.5458\n",
      "Epoch 320/600\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.1087 - accuracy: 0.5369 - val_loss: 1.0891 - val_accuracy: 0.5458\n",
      "Epoch 321/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1086 - accuracy: 0.5367 - val_loss: 1.0883 - val_accuracy: 0.5392\n",
      "Epoch 322/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1086 - accuracy: 0.5351 - val_loss: 1.0880 - val_accuracy: 0.5394\n",
      "Epoch 323/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1072 - accuracy: 0.5396 - val_loss: 1.0886 - val_accuracy: 0.5453\n",
      "Epoch 324/600\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1070 - accuracy: 0.5367 - val_loss: 1.0885 - val_accuracy: 0.5438\n",
      "Epoch 325/600\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.1064 - accuracy: 0.5350 - val_loss: 1.0881 - val_accuracy: 0.5392\n",
      "Epoch 326/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1075 - accuracy: 0.5351 - val_loss: 1.0881 - val_accuracy: 0.5409\n",
      "Epoch 327/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1033 - accuracy: 0.5353 - val_loss: 1.0884 - val_accuracy: 0.5468\n",
      "Epoch 328/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1053 - accuracy: 0.5359 - val_loss: 1.0877 - val_accuracy: 0.5429\n",
      "Epoch 329/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1070 - accuracy: 0.5363 - val_loss: 1.0874 - val_accuracy: 0.5433\n",
      "Epoch 330/600\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.1085 - accuracy: 0.5376 - val_loss: 1.0876 - val_accuracy: 0.5438\n",
      "Epoch 331/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1051 - accuracy: 0.5366 - val_loss: 1.0873 - val_accuracy: 0.5423\n",
      "Epoch 332/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1092 - accuracy: 0.5338 - val_loss: 1.0872 - val_accuracy: 0.5419\n",
      "Epoch 333/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1101 - accuracy: 0.5359 - val_loss: 1.0875 - val_accuracy: 0.5474\n",
      "Epoch 334/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1043 - accuracy: 0.5382 - val_loss: 1.0873 - val_accuracy: 0.5411\n",
      "Epoch 335/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1090 - accuracy: 0.5335 - val_loss: 1.0873 - val_accuracy: 0.5417\n",
      "Epoch 336/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1048 - accuracy: 0.5353 - val_loss: 1.0872 - val_accuracy: 0.5462\n",
      "Epoch 337/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1055 - accuracy: 0.5352 - val_loss: 1.0871 - val_accuracy: 0.5470\n",
      "Epoch 338/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1068 - accuracy: 0.5343 - val_loss: 1.0869 - val_accuracy: 0.5452\n",
      "Epoch 339/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1071 - accuracy: 0.5357 - val_loss: 1.0867 - val_accuracy: 0.5419\n",
      "Epoch 340/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1077 - accuracy: 0.5356 - val_loss: 1.0868 - val_accuracy: 0.5423\n",
      "Epoch 341/600\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 1.1049 - accuracy: 0.5391 - val_loss: 1.0874 - val_accuracy: 0.5465\n",
      "Epoch 342/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1053 - accuracy: 0.5357 - val_loss: 1.0871 - val_accuracy: 0.5453\n",
      "Epoch 343/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1073 - accuracy: 0.5337 - val_loss: 1.0867 - val_accuracy: 0.5431\n",
      "Epoch 344/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1090 - accuracy: 0.5333 - val_loss: 1.0868 - val_accuracy: 0.5430\n",
      "Epoch 345/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1073 - accuracy: 0.5375 - val_loss: 1.0868 - val_accuracy: 0.5479\n",
      "Epoch 346/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1044 - accuracy: 0.5387 - val_loss: 1.0861 - val_accuracy: 0.5433\n",
      "Epoch 347/600\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.1052 - accuracy: 0.5362 - val_loss: 1.0859 - val_accuracy: 0.5430\n",
      "Epoch 348/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.1061 - accuracy: 0.5330 - val_loss: 1.0863 - val_accuracy: 0.5460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/600\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.1045 - accuracy: 0.5424 - val_loss: 1.0856 - val_accuracy: 0.5430\n",
      "Epoch 350/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1063 - accuracy: 0.5347 - val_loss: 1.0855 - val_accuracy: 0.5398\n",
      "Epoch 351/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1048 - accuracy: 0.5381 - val_loss: 1.0862 - val_accuracy: 0.5469\n",
      "Epoch 352/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1052 - accuracy: 0.5381 - val_loss: 1.0864 - val_accuracy: 0.5473\n",
      "Epoch 353/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1065 - accuracy: 0.5310 - val_loss: 1.0860 - val_accuracy: 0.5480\n",
      "Epoch 354/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1074 - accuracy: 0.5355 - val_loss: 1.0857 - val_accuracy: 0.5413\n",
      "Epoch 355/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1046 - accuracy: 0.5404 - val_loss: 1.0855 - val_accuracy: 0.5411\n",
      "Epoch 356/600\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.1077 - accuracy: 0.5371 - val_loss: 1.0853 - val_accuracy: 0.5422\n",
      "Epoch 357/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1051 - accuracy: 0.5356 - val_loss: 1.0856 - val_accuracy: 0.5505\n",
      "Epoch 358/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1044 - accuracy: 0.5395 - val_loss: 1.0853 - val_accuracy: 0.5417\n",
      "Epoch 359/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1037 - accuracy: 0.5352 - val_loss: 1.0853 - val_accuracy: 0.5407\n",
      "Epoch 360/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1023 - accuracy: 0.5384 - val_loss: 1.0855 - val_accuracy: 0.5479\n",
      "Epoch 361/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1050 - accuracy: 0.5358 - val_loss: 1.0851 - val_accuracy: 0.5470\n",
      "Epoch 362/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1039 - accuracy: 0.5383 - val_loss: 1.0849 - val_accuracy: 0.5426\n",
      "Epoch 363/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1041 - accuracy: 0.5352 - val_loss: 1.0849 - val_accuracy: 0.5417\n",
      "Epoch 364/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1047 - accuracy: 0.5349 - val_loss: 1.0852 - val_accuracy: 0.5479\n",
      "Epoch 365/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1068 - accuracy: 0.5341 - val_loss: 1.0854 - val_accuracy: 0.5488\n",
      "Epoch 366/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1053 - accuracy: 0.5377 - val_loss: 1.0848 - val_accuracy: 0.5399\n",
      "Epoch 367/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1053 - accuracy: 0.5364 - val_loss: 1.0849 - val_accuracy: 0.5477\n",
      "Epoch 368/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1022 - accuracy: 0.5378 - val_loss: 1.0849 - val_accuracy: 0.5504\n",
      "Epoch 369/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1037 - accuracy: 0.5368 - val_loss: 1.0843 - val_accuracy: 0.5487\n",
      "Epoch 370/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1028 - accuracy: 0.5398 - val_loss: 1.0838 - val_accuracy: 0.5441\n",
      "Epoch 371/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1052 - accuracy: 0.5351 - val_loss: 1.0843 - val_accuracy: 0.5477\n",
      "Epoch 372/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1032 - accuracy: 0.5361 - val_loss: 1.0846 - val_accuracy: 0.5481\n",
      "Epoch 373/600\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.1049 - accuracy: 0.5393 - val_loss: 1.0843 - val_accuracy: 0.5429\n",
      "Epoch 374/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1039 - accuracy: 0.5364 - val_loss: 1.0843 - val_accuracy: 0.5430\n",
      "Epoch 375/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1051 - accuracy: 0.5337 - val_loss: 1.0850 - val_accuracy: 0.5511\n",
      "Epoch 376/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1022 - accuracy: 0.5387 - val_loss: 1.0846 - val_accuracy: 0.5497\n",
      "Epoch 377/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1015 - accuracy: 0.5386 - val_loss: 1.0844 - val_accuracy: 0.5426\n",
      "Epoch 378/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1004 - accuracy: 0.5361 - val_loss: 1.0842 - val_accuracy: 0.5477\n",
      "Epoch 379/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1047 - accuracy: 0.5371 - val_loss: 1.0843 - val_accuracy: 0.5488\n",
      "Epoch 380/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1045 - accuracy: 0.5367 - val_loss: 1.0841 - val_accuracy: 0.5472\n",
      "Epoch 381/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1039 - accuracy: 0.5390 - val_loss: 1.0840 - val_accuracy: 0.5462\n",
      "Epoch 382/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1049 - accuracy: 0.5377 - val_loss: 1.0841 - val_accuracy: 0.5495\n",
      "Epoch 383/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1045 - accuracy: 0.5391 - val_loss: 1.0843 - val_accuracy: 0.5493\n",
      "Epoch 384/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1028 - accuracy: 0.5355 - val_loss: 1.0844 - val_accuracy: 0.5489\n",
      "Epoch 385/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1006 - accuracy: 0.5399 - val_loss: 1.0847 - val_accuracy: 0.5491\n",
      "Epoch 386/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1033 - accuracy: 0.5343 - val_loss: 1.0839 - val_accuracy: 0.5472\n",
      "Epoch 387/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1040 - accuracy: 0.5361 - val_loss: 1.0836 - val_accuracy: 0.5458\n",
      "Epoch 388/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1034 - accuracy: 0.5375 - val_loss: 1.0837 - val_accuracy: 0.5500\n",
      "Epoch 389/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1037 - accuracy: 0.5388 - val_loss: 1.0835 - val_accuracy: 0.5532\n",
      "Epoch 390/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1032 - accuracy: 0.5401 - val_loss: 1.0830 - val_accuracy: 0.5489\n",
      "Epoch 391/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1030 - accuracy: 0.5375 - val_loss: 1.0833 - val_accuracy: 0.5474\n",
      "Epoch 392/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1005 - accuracy: 0.5398 - val_loss: 1.0838 - val_accuracy: 0.5526\n",
      "Epoch 393/600\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.0990 - accuracy: 0.5444 - val_loss: 1.0833 - val_accuracy: 0.5499\n",
      "Epoch 394/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1063 - accuracy: 0.5373 - val_loss: 1.0827 - val_accuracy: 0.5446\n",
      "Epoch 395/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1021 - accuracy: 0.5412 - val_loss: 1.0831 - val_accuracy: 0.5516\n",
      "Epoch 396/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1015 - accuracy: 0.5369 - val_loss: 1.0835 - val_accuracy: 0.5511\n",
      "Epoch 397/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1014 - accuracy: 0.5377 - val_loss: 1.0832 - val_accuracy: 0.5511\n",
      "Epoch 398/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.1016 - accuracy: 0.5366 - val_loss: 1.0830 - val_accuracy: 0.5493\n",
      "Epoch 399/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1009 - accuracy: 0.5395 - val_loss: 1.0835 - val_accuracy: 0.5493\n",
      "Epoch 400/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1033 - accuracy: 0.5443 - val_loss: 1.0830 - val_accuracy: 0.5515\n",
      "Epoch 401/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1016 - accuracy: 0.5389 - val_loss: 1.0829 - val_accuracy: 0.5474\n",
      "Epoch 402/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0999 - accuracy: 0.5390 - val_loss: 1.0829 - val_accuracy: 0.5491\n",
      "Epoch 403/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1006 - accuracy: 0.5383 - val_loss: 1.0827 - val_accuracy: 0.5473\n",
      "Epoch 404/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1016 - accuracy: 0.5370 - val_loss: 1.0828 - val_accuracy: 0.5468\n",
      "Epoch 405/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1044 - accuracy: 0.5378 - val_loss: 1.0832 - val_accuracy: 0.5534\n",
      "Epoch 406/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1015 - accuracy: 0.5415 - val_loss: 1.0828 - val_accuracy: 0.5522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1021 - accuracy: 0.5389 - val_loss: 1.0824 - val_accuracy: 0.5481\n",
      "Epoch 408/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1025 - accuracy: 0.5398 - val_loss: 1.0828 - val_accuracy: 0.5516\n",
      "Epoch 409/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1007 - accuracy: 0.5430 - val_loss: 1.0832 - val_accuracy: 0.5522\n",
      "Epoch 410/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1016 - accuracy: 0.5420 - val_loss: 1.0824 - val_accuracy: 0.5456\n",
      "Epoch 411/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1012 - accuracy: 0.5376 - val_loss: 1.0825 - val_accuracy: 0.5446\n",
      "Epoch 412/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1023 - accuracy: 0.5359 - val_loss: 1.0826 - val_accuracy: 0.5495\n",
      "Epoch 413/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1045 - accuracy: 0.5379 - val_loss: 1.0826 - val_accuracy: 0.5481\n",
      "Epoch 414/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1032 - accuracy: 0.5378 - val_loss: 1.0825 - val_accuracy: 0.5461\n",
      "Epoch 415/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1010 - accuracy: 0.5432 - val_loss: 1.0822 - val_accuracy: 0.5496\n",
      "Epoch 416/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1029 - accuracy: 0.5408 - val_loss: 1.0820 - val_accuracy: 0.5487\n",
      "Epoch 417/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0976 - accuracy: 0.5420 - val_loss: 1.0819 - val_accuracy: 0.5487\n",
      "Epoch 418/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1003 - accuracy: 0.5408 - val_loss: 1.0820 - val_accuracy: 0.5497\n",
      "Epoch 419/600\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0979 - accuracy: 0.5427 - val_loss: 1.0817 - val_accuracy: 0.5495\n",
      "Epoch 420/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1010 - accuracy: 0.5373 - val_loss: 1.0818 - val_accuracy: 0.5509\n",
      "Epoch 421/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1003 - accuracy: 0.5414 - val_loss: 1.0823 - val_accuracy: 0.5519\n",
      "Epoch 422/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0990 - accuracy: 0.5422 - val_loss: 1.0818 - val_accuracy: 0.5505\n",
      "Epoch 423/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1006 - accuracy: 0.5400 - val_loss: 1.0816 - val_accuracy: 0.5462\n",
      "Epoch 424/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1010 - accuracy: 0.5402 - val_loss: 1.0817 - val_accuracy: 0.5497\n",
      "Epoch 425/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0991 - accuracy: 0.5425 - val_loss: 1.0819 - val_accuracy: 0.5511\n",
      "Epoch 426/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0977 - accuracy: 0.5421 - val_loss: 1.0812 - val_accuracy: 0.5496\n",
      "Epoch 427/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1027 - accuracy: 0.5395 - val_loss: 1.0810 - val_accuracy: 0.5466\n",
      "Epoch 428/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0979 - accuracy: 0.5393 - val_loss: 1.0812 - val_accuracy: 0.5476\n",
      "Epoch 429/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0989 - accuracy: 0.5395 - val_loss: 1.0810 - val_accuracy: 0.5485\n",
      "Epoch 430/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0988 - accuracy: 0.5436 - val_loss: 1.0813 - val_accuracy: 0.5499\n",
      "Epoch 431/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1020 - accuracy: 0.5393 - val_loss: 1.0820 - val_accuracy: 0.5524\n",
      "Epoch 432/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0978 - accuracy: 0.5449 - val_loss: 1.0813 - val_accuracy: 0.5500\n",
      "Epoch 433/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1025 - accuracy: 0.5348 - val_loss: 1.0811 - val_accuracy: 0.5473\n",
      "Epoch 434/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1018 - accuracy: 0.5378 - val_loss: 1.0814 - val_accuracy: 0.5536\n",
      "Epoch 435/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0988 - accuracy: 0.5405 - val_loss: 1.0815 - val_accuracy: 0.5519\n",
      "Epoch 436/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1014 - accuracy: 0.5410 - val_loss: 1.0810 - val_accuracy: 0.5519\n",
      "Epoch 437/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1004 - accuracy: 0.5397 - val_loss: 1.0809 - val_accuracy: 0.5503\n",
      "Epoch 438/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1003 - accuracy: 0.5385 - val_loss: 1.0810 - val_accuracy: 0.5528\n",
      "Epoch 439/600\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0981 - accuracy: 0.5445 - val_loss: 1.0814 - val_accuracy: 0.5539\n",
      "Epoch 440/600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1042 - accuracy: 0.5401 - val_loss: 1.0811 - val_accuracy: 0.5526\n",
      "Epoch 441/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1020 - accuracy: 0.5416 - val_loss: 1.0817 - val_accuracy: 0.5509\n",
      "Epoch 442/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1021 - accuracy: 0.5420 - val_loss: 1.0817 - val_accuracy: 0.5527\n",
      "Epoch 443/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0981 - accuracy: 0.5437 - val_loss: 1.0812 - val_accuracy: 0.5505\n",
      "Epoch 444/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0974 - accuracy: 0.5428 - val_loss: 1.0808 - val_accuracy: 0.5505\n",
      "Epoch 445/600\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.0981 - accuracy: 0.5420 - val_loss: 1.0807 - val_accuracy: 0.5550\n",
      "Epoch 446/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0980 - accuracy: 0.5414 - val_loss: 1.0800 - val_accuracy: 0.5491\n",
      "Epoch 447/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0989 - accuracy: 0.5402 - val_loss: 1.0802 - val_accuracy: 0.5511\n",
      "Epoch 448/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0994 - accuracy: 0.5413 - val_loss: 1.0810 - val_accuracy: 0.5515\n",
      "Epoch 449/600\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.0971 - accuracy: 0.5432 - val_loss: 1.0808 - val_accuracy: 0.5527\n",
      "Epoch 450/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1033 - accuracy: 0.5393 - val_loss: 1.0804 - val_accuracy: 0.5501\n",
      "Epoch 451/600\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1000 - accuracy: 0.5429 - val_loss: 1.0803 - val_accuracy: 0.5539\n",
      "Epoch 452/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0986 - accuracy: 0.5448 - val_loss: 1.0801 - val_accuracy: 0.5515\n",
      "Epoch 453/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1000 - accuracy: 0.5367 - val_loss: 1.0802 - val_accuracy: 0.5531\n",
      "Epoch 454/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1029 - accuracy: 0.5401 - val_loss: 1.0806 - val_accuracy: 0.5519\n",
      "Epoch 455/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0989 - accuracy: 0.5396 - val_loss: 1.0805 - val_accuracy: 0.5527\n",
      "Epoch 456/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1000 - accuracy: 0.5435 - val_loss: 1.0803 - val_accuracy: 0.5523\n",
      "Epoch 457/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0960 - accuracy: 0.5399 - val_loss: 1.0804 - val_accuracy: 0.5527\n",
      "Epoch 458/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0984 - accuracy: 0.5430 - val_loss: 1.0808 - val_accuracy: 0.5557\n",
      "Epoch 459/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0954 - accuracy: 0.5434 - val_loss: 1.0801 - val_accuracy: 0.5509\n",
      "Epoch 460/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0985 - accuracy: 0.5402 - val_loss: 1.0797 - val_accuracy: 0.5532\n",
      "Epoch 461/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0982 - accuracy: 0.5404 - val_loss: 1.0800 - val_accuracy: 0.5534\n",
      "Epoch 462/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0985 - accuracy: 0.5433 - val_loss: 1.0793 - val_accuracy: 0.5500\n",
      "Epoch 463/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0956 - accuracy: 0.5428 - val_loss: 1.0794 - val_accuracy: 0.5503\n",
      "Epoch 464/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0978 - accuracy: 0.5414 - val_loss: 1.0797 - val_accuracy: 0.5550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0968 - accuracy: 0.5427 - val_loss: 1.0794 - val_accuracy: 0.5531\n",
      "Epoch 466/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1007 - accuracy: 0.5420 - val_loss: 1.0793 - val_accuracy: 0.5553\n",
      "Epoch 467/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1013 - accuracy: 0.5421 - val_loss: 1.0792 - val_accuracy: 0.5536\n",
      "Epoch 468/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0979 - accuracy: 0.5439 - val_loss: 1.0798 - val_accuracy: 0.5532\n",
      "Epoch 469/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0996 - accuracy: 0.5434 - val_loss: 1.0796 - val_accuracy: 0.5536\n",
      "Epoch 470/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.0985 - accuracy: 0.5425 - val_loss: 1.0792 - val_accuracy: 0.5549\n",
      "Epoch 471/600\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.0974 - accuracy: 0.5403 - val_loss: 1.0794 - val_accuracy: 0.5523\n",
      "Epoch 472/600\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.0989 - accuracy: 0.5432 - val_loss: 1.0797 - val_accuracy: 0.5518\n",
      "Epoch 473/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0960 - accuracy: 0.5438 - val_loss: 1.0792 - val_accuracy: 0.5535\n",
      "Epoch 474/600\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0995 - accuracy: 0.5406 - val_loss: 1.0787 - val_accuracy: 0.5520\n",
      "Epoch 475/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0934 - accuracy: 0.5420 - val_loss: 1.0789 - val_accuracy: 0.5518\n",
      "Epoch 476/600\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.0972 - accuracy: 0.5439 - val_loss: 1.0785 - val_accuracy: 0.5553\n",
      "Epoch 477/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0965 - accuracy: 0.5398 - val_loss: 1.0783 - val_accuracy: 0.5516\n",
      "Epoch 478/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0983 - accuracy: 0.5403 - val_loss: 1.0782 - val_accuracy: 0.5544\n",
      "Epoch 479/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1004 - accuracy: 0.5432 - val_loss: 1.0782 - val_accuracy: 0.5536\n",
      "Epoch 480/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0965 - accuracy: 0.5429 - val_loss: 1.0785 - val_accuracy: 0.5540\n",
      "Epoch 481/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0973 - accuracy: 0.5409 - val_loss: 1.0784 - val_accuracy: 0.5549\n",
      "Epoch 482/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0954 - accuracy: 0.5451 - val_loss: 1.0788 - val_accuracy: 0.5557\n",
      "Epoch 483/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0956 - accuracy: 0.5447 - val_loss: 1.0790 - val_accuracy: 0.5553\n",
      "Epoch 484/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0970 - accuracy: 0.5457 - val_loss: 1.0785 - val_accuracy: 0.5559\n",
      "Epoch 485/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0930 - accuracy: 0.5436 - val_loss: 1.0780 - val_accuracy: 0.5515\n",
      "Epoch 486/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.0993 - accuracy: 0.5424 - val_loss: 1.0791 - val_accuracy: 0.5547\n",
      "Epoch 487/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0985 - accuracy: 0.5448 - val_loss: 1.0788 - val_accuracy: 0.5542\n",
      "Epoch 488/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0955 - accuracy: 0.5400 - val_loss: 1.0782 - val_accuracy: 0.5534\n",
      "Epoch 489/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0938 - accuracy: 0.5424 - val_loss: 1.0785 - val_accuracy: 0.5554\n",
      "Epoch 490/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0955 - accuracy: 0.5467 - val_loss: 1.0784 - val_accuracy: 0.5551\n",
      "Epoch 491/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0965 - accuracy: 0.5426 - val_loss: 1.0780 - val_accuracy: 0.5536\n",
      "Epoch 492/600\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0947 - accuracy: 0.5444 - val_loss: 1.0778 - val_accuracy: 0.5540\n",
      "Epoch 493/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.0986 - accuracy: 0.5414 - val_loss: 1.0775 - val_accuracy: 0.5540\n",
      "Epoch 494/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1001 - accuracy: 0.5419 - val_loss: 1.0773 - val_accuracy: 0.5522\n",
      "Epoch 495/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0968 - accuracy: 0.5405 - val_loss: 1.0778 - val_accuracy: 0.5547\n",
      "Epoch 496/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0944 - accuracy: 0.5455 - val_loss: 1.0784 - val_accuracy: 0.5540\n",
      "Epoch 497/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0959 - accuracy: 0.5428 - val_loss: 1.0777 - val_accuracy: 0.5536\n",
      "Epoch 498/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.0954 - accuracy: 0.5438 - val_loss: 1.0778 - val_accuracy: 0.5569\n",
      "Epoch 499/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0968 - accuracy: 0.5436 - val_loss: 1.0778 - val_accuracy: 0.5555\n",
      "Epoch 500/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0977 - accuracy: 0.5410 - val_loss: 1.0773 - val_accuracy: 0.5501\n",
      "Epoch 501/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0968 - accuracy: 0.5420 - val_loss: 1.0777 - val_accuracy: 0.5539\n",
      "Epoch 502/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0984 - accuracy: 0.5417 - val_loss: 1.0778 - val_accuracy: 0.5553\n",
      "Epoch 503/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0965 - accuracy: 0.5421 - val_loss: 1.0779 - val_accuracy: 0.5565\n",
      "Epoch 504/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0957 - accuracy: 0.5428 - val_loss: 1.0780 - val_accuracy: 0.5557\n",
      "Epoch 505/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0945 - accuracy: 0.5412 - val_loss: 1.0777 - val_accuracy: 0.5555\n",
      "Epoch 506/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0939 - accuracy: 0.5399 - val_loss: 1.0782 - val_accuracy: 0.5544\n",
      "Epoch 507/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0964 - accuracy: 0.5446 - val_loss: 1.0778 - val_accuracy: 0.5543\n",
      "Epoch 508/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0977 - accuracy: 0.5444 - val_loss: 1.0775 - val_accuracy: 0.5555\n",
      "Epoch 509/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0912 - accuracy: 0.5475 - val_loss: 1.0778 - val_accuracy: 0.5527\n",
      "Epoch 510/600\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.0926 - accuracy: 0.5475 - val_loss: 1.0774 - val_accuracy: 0.5518\n",
      "Epoch 511/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0931 - accuracy: 0.5420 - val_loss: 1.0774 - val_accuracy: 0.5540\n",
      "Epoch 512/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0955 - accuracy: 0.5455 - val_loss: 1.0778 - val_accuracy: 0.5543\n",
      "Epoch 513/600\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.0972 - accuracy: 0.5439 - val_loss: 1.0778 - val_accuracy: 0.5549\n",
      "Epoch 514/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0960 - accuracy: 0.5422 - val_loss: 1.0779 - val_accuracy: 0.5527\n",
      "Epoch 515/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0953 - accuracy: 0.5434 - val_loss: 1.0779 - val_accuracy: 0.5524\n",
      "Epoch 516/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0952 - accuracy: 0.5428 - val_loss: 1.0779 - val_accuracy: 0.5543\n",
      "Epoch 517/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0942 - accuracy: 0.5495 - val_loss: 1.0773 - val_accuracy: 0.5543\n",
      "Epoch 518/600\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.0953 - accuracy: 0.5444 - val_loss: 1.0763 - val_accuracy: 0.5553\n",
      "Epoch 519/600\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.0926 - accuracy: 0.5438 - val_loss: 1.0765 - val_accuracy: 0.5543\n",
      "Epoch 520/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0923 - accuracy: 0.5432 - val_loss: 1.0770 - val_accuracy: 0.5555\n",
      "Epoch 521/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0926 - accuracy: 0.5438 - val_loss: 1.0770 - val_accuracy: 0.5557\n",
      "Epoch 522/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0944 - accuracy: 0.5449 - val_loss: 1.0769 - val_accuracy: 0.5555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/600\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.0927 - accuracy: 0.5433 - val_loss: 1.0766 - val_accuracy: 0.5555\n",
      "Epoch 524/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0969 - accuracy: 0.5440 - val_loss: 1.0766 - val_accuracy: 0.5515\n",
      "Epoch 525/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0928 - accuracy: 0.5440 - val_loss: 1.0777 - val_accuracy: 0.5546\n",
      "Epoch 526/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0939 - accuracy: 0.5481 - val_loss: 1.0770 - val_accuracy: 0.5544\n",
      "Epoch 527/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0950 - accuracy: 0.5433 - val_loss: 1.0767 - val_accuracy: 0.5530\n",
      "Epoch 528/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0923 - accuracy: 0.5446 - val_loss: 1.0771 - val_accuracy: 0.5540\n",
      "Epoch 529/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0926 - accuracy: 0.5463 - val_loss: 1.0775 - val_accuracy: 0.5538\n",
      "Epoch 530/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0940 - accuracy: 0.5452 - val_loss: 1.0763 - val_accuracy: 0.5554\n",
      "Epoch 531/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0942 - accuracy: 0.5418 - val_loss: 1.0762 - val_accuracy: 0.5473\n",
      "Epoch 532/600\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0946 - accuracy: 0.5428 - val_loss: 1.0772 - val_accuracy: 0.5554\n",
      "Epoch 533/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0937 - accuracy: 0.5440 - val_loss: 1.0764 - val_accuracy: 0.5539\n",
      "Epoch 534/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0934 - accuracy: 0.5457 - val_loss: 1.0759 - val_accuracy: 0.5532\n",
      "Epoch 535/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0923 - accuracy: 0.5440 - val_loss: 1.0760 - val_accuracy: 0.5547\n",
      "Epoch 536/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0877 - accuracy: 0.5462 - val_loss: 1.0768 - val_accuracy: 0.5540\n",
      "Epoch 537/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0932 - accuracy: 0.5446 - val_loss: 1.0764 - val_accuracy: 0.5547\n",
      "Epoch 538/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0938 - accuracy: 0.5438 - val_loss: 1.0759 - val_accuracy: 0.5549\n",
      "Epoch 539/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0912 - accuracy: 0.5455 - val_loss: 1.0764 - val_accuracy: 0.5549\n",
      "Epoch 540/600\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0924 - accuracy: 0.5446 - val_loss: 1.0757 - val_accuracy: 0.5544\n",
      "Epoch 541/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0950 - accuracy: 0.5443 - val_loss: 1.0755 - val_accuracy: 0.5554\n",
      "Epoch 542/600\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0937 - accuracy: 0.5422 - val_loss: 1.0760 - val_accuracy: 0.5543\n",
      "Epoch 543/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0908 - accuracy: 0.5453 - val_loss: 1.0760 - val_accuracy: 0.5544\n",
      "Epoch 544/600\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.0952 - accuracy: 0.5453 - val_loss: 1.0761 - val_accuracy: 0.5544\n",
      "Epoch 545/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0927 - accuracy: 0.5466 - val_loss: 1.0757 - val_accuracy: 0.5543\n",
      "Epoch 546/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0936 - accuracy: 0.5449 - val_loss: 1.0757 - val_accuracy: 0.5539\n",
      "Epoch 547/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0937 - accuracy: 0.5435 - val_loss: 1.0758 - val_accuracy: 0.5538\n",
      "Epoch 548/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0954 - accuracy: 0.5432 - val_loss: 1.0751 - val_accuracy: 0.5543\n",
      "Epoch 549/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0940 - accuracy: 0.5457 - val_loss: 1.0755 - val_accuracy: 0.5543\n",
      "Epoch 550/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0918 - accuracy: 0.5476 - val_loss: 1.0756 - val_accuracy: 0.5551\n",
      "Epoch 551/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0884 - accuracy: 0.5481 - val_loss: 1.0751 - val_accuracy: 0.5554\n",
      "Epoch 552/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0922 - accuracy: 0.5440 - val_loss: 1.0750 - val_accuracy: 0.5561\n",
      "Epoch 553/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0932 - accuracy: 0.5454 - val_loss: 1.0756 - val_accuracy: 0.5553\n",
      "Epoch 554/600\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0918 - accuracy: 0.5432 - val_loss: 1.0755 - val_accuracy: 0.5550\n",
      "Epoch 555/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0934 - accuracy: 0.5441 - val_loss: 1.0749 - val_accuracy: 0.5557\n",
      "Epoch 556/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0920 - accuracy: 0.5466 - val_loss: 1.0752 - val_accuracy: 0.5551\n",
      "Epoch 557/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0944 - accuracy: 0.5434 - val_loss: 1.0752 - val_accuracy: 0.5543\n",
      "Epoch 558/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0968 - accuracy: 0.5422 - val_loss: 1.0755 - val_accuracy: 0.5558\n",
      "Epoch 559/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0920 - accuracy: 0.5456 - val_loss: 1.0757 - val_accuracy: 0.5555\n",
      "Epoch 560/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0929 - accuracy: 0.5450 - val_loss: 1.0752 - val_accuracy: 0.5555\n",
      "Epoch 561/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0922 - accuracy: 0.5416 - val_loss: 1.0757 - val_accuracy: 0.5539\n",
      "Epoch 562/600\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0940 - accuracy: 0.5438 - val_loss: 1.0755 - val_accuracy: 0.5543\n",
      "Epoch 563/600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0927 - accuracy: 0.5435 - val_loss: 1.0749 - val_accuracy: 0.5535\n",
      "Epoch 564/600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0908 - accuracy: 0.5473 - val_loss: 1.0756 - val_accuracy: 0.5553\n",
      "Epoch 565/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.0936 - accuracy: 0.5448 - val_loss: 1.0756 - val_accuracy: 0.5550\n",
      "Epoch 566/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0930 - accuracy: 0.5462 - val_loss: 1.0749 - val_accuracy: 0.5561\n",
      "Epoch 567/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0919 - accuracy: 0.5443 - val_loss: 1.0751 - val_accuracy: 0.5561\n",
      "Epoch 568/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0904 - accuracy: 0.5475 - val_loss: 1.0759 - val_accuracy: 0.5555\n",
      "Epoch 569/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0916 - accuracy: 0.5481 - val_loss: 1.0752 - val_accuracy: 0.5555\n",
      "Epoch 570/600\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0916 - accuracy: 0.5440 - val_loss: 1.0750 - val_accuracy: 0.5555\n",
      "Epoch 571/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0938 - accuracy: 0.5459 - val_loss: 1.0751 - val_accuracy: 0.5554\n",
      "Epoch 572/600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0930 - accuracy: 0.5465 - val_loss: 1.0746 - val_accuracy: 0.5551\n",
      "Epoch 573/600\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0927 - accuracy: 0.5450 - val_loss: 1.0744 - val_accuracy: 0.5551\n",
      "Epoch 574/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.0914 - accuracy: 0.5473 - val_loss: 1.0745 - val_accuracy: 0.5554\n",
      "Epoch 575/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0931 - accuracy: 0.5461 - val_loss: 1.0740 - val_accuracy: 0.5565\n",
      "Epoch 576/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0900 - accuracy: 0.5457 - val_loss: 1.0740 - val_accuracy: 0.5554\n",
      "Epoch 577/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0937 - accuracy: 0.5452 - val_loss: 1.0744 - val_accuracy: 0.5551\n",
      "Epoch 578/600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0916 - accuracy: 0.5461 - val_loss: 1.0748 - val_accuracy: 0.5550\n",
      "Epoch 579/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0883 - accuracy: 0.5476 - val_loss: 1.0744 - val_accuracy: 0.5543\n",
      "Epoch 580/600\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0905 - accuracy: 0.5501 - val_loss: 1.0743 - val_accuracy: 0.5553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0892 - accuracy: 0.5471 - val_loss: 1.0742 - val_accuracy: 0.5561\n",
      "Epoch 582/600\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.0917 - accuracy: 0.5440 - val_loss: 1.0743 - val_accuracy: 0.5550\n",
      "Epoch 583/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0885 - accuracy: 0.5487 - val_loss: 1.0742 - val_accuracy: 0.5542\n",
      "Epoch 584/600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0938 - accuracy: 0.5465 - val_loss: 1.0741 - val_accuracy: 0.5547\n",
      "Epoch 585/600\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0907 - accuracy: 0.5474 - val_loss: 1.0742 - val_accuracy: 0.5558\n",
      "Epoch 586/600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0917 - accuracy: 0.5505 - val_loss: 1.0743 - val_accuracy: 0.5554\n",
      "Epoch 587/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0956 - accuracy: 0.5422 - val_loss: 1.0742 - val_accuracy: 0.5557\n",
      "Epoch 588/600\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0862 - accuracy: 0.5461 - val_loss: 1.0746 - val_accuracy: 0.5553\n",
      "Epoch 589/600\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.0888 - accuracy: 0.5460 - val_loss: 1.0745 - val_accuracy: 0.5553\n",
      "Epoch 590/600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0901 - accuracy: 0.5482 - val_loss: 1.0742 - val_accuracy: 0.5554\n",
      "Epoch 591/600\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0942 - accuracy: 0.5440 - val_loss: 1.0745 - val_accuracy: 0.5563\n",
      "Epoch 592/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0932 - accuracy: 0.5483 - val_loss: 1.0749 - val_accuracy: 0.5550\n",
      "Epoch 593/600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0919 - accuracy: 0.5457 - val_loss: 1.0748 - val_accuracy: 0.5562\n",
      "Epoch 594/600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0937 - accuracy: 0.5487 - val_loss: 1.0745 - val_accuracy: 0.5567\n",
      "Epoch 595/600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0925 - accuracy: 0.5410 - val_loss: 1.0743 - val_accuracy: 0.5565\n",
      "Epoch 596/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0943 - accuracy: 0.5469 - val_loss: 1.0748 - val_accuracy: 0.5550\n",
      "Epoch 597/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0917 - accuracy: 0.5440 - val_loss: 1.0739 - val_accuracy: 0.5550\n",
      "Epoch 598/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0911 - accuracy: 0.5494 - val_loss: 1.0736 - val_accuracy: 0.5544\n",
      "Epoch 599/600\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0911 - accuracy: 0.5479 - val_loss: 1.0740 - val_accuracy: 0.5538\n",
      "Epoch 600/600\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0900 - accuracy: 0.5502 - val_loss: 1.0741 - val_accuracy: 0.5538\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(len(columns[0]),)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.33)\n",
    "\n",
    "def display_training_graph(history):\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['val_loss', 'loss'], loc='upper right')\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "display_training_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
